{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import torchaudio\n",
    "import csv\n",
    "import string\n",
    "\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torchaudio.transforms import TimeMasking, FrequencyMasking\n",
    "from torchvision.ops import SqueezeExcitation\n",
    "from torchinfo import summary\n",
    "from torchsummary import summary\n",
    "from torchvision.ops import SqueezeExcitation\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from scipy.io import wavfile\n",
    "from functools import reduce\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_s = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "labels = list(keys_s)\n",
    "keys = [k + '.wav' for k in labels]\n",
    "data_dict = {'Key':[], 'File':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_noise_to_stroke(stroke, noise_factor=None):\n",
    "    # print(stroke.shape)\n",
    "    noise = torch.randn_like(stroke)\n",
    "    return stroke + noise_factor * noise\n",
    "\n",
    "def isolator(signal, sample_rate, size, scan, before, after, threshold, show=False):\n",
    "    strokes = []\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(signal, sr=sample_rate)\n",
    "    fft = librosa.stft(signal, n_fft=size, hop_length=scan)\n",
    "    energy = np.abs(np.sum(fft, axis=0)).astype(float)\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(energy)\n",
    "    threshed = energy > threshold\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(threshed.astype(float))\n",
    "    peaks = np.where(threshed)[0]\n",
    "    peak_count = len(peaks)\n",
    "    prev_end = sample_rate * 0.1 * (-1)\n",
    "    for i in range(peak_count):\n",
    "        this_peak = peaks[i]\n",
    "        timestamp = (this_peak * scan) + size // 2\n",
    "        if timestamp > prev_end + (0.1 * sample_rate):\n",
    "            keystroke = signal[timestamp - before:timestamp + after]\n",
    "            strokes.append(torch.tensor(keystroke)[None, :])\n",
    "            if show:\n",
    "                plt.figure(figsize=(7, 2))\n",
    "                librosa.display.waveshow(keystroke, sr=sample_rate)\n",
    "            prev_end = timestamp + after\n",
    "    return strokes\n",
    "\n",
    "def convert_to_df_with_noise(audio_dir, noise_factor=None):\n",
    "    \"\"\"\n",
    "    Processes each audio file by isolating strokes, adds noise to each stroke,\n",
    "    and stores the strokes with labels in a dataframe.\n",
    "    \"\"\"\n",
    "    # Generate a list of .wav files in the provided directory\n",
    "    keys = sorted([f for f in os.listdir(audio_dir) if f.endswith('.wav')])\n",
    "    \n",
    "    data_dict = {'Key': [], 'File': []}\n",
    "    \n",
    "    # If your labels are inferred from file names, you can extract them here.\n",
    "    # For example, if the file is 'a.wav', you might want to use 'a' as the label.\n",
    "    def extract_label(filename):\n",
    "        base = os.path.splitext(filename)[0]\n",
    "        return base  # or apply any mapping you need\n",
    "\n",
    "    for file in keys:\n",
    "        loc = os.path.join(audio_dir, file)\n",
    "        samples, sample_rate = librosa.load(loc, sr=None)\n",
    "        strokes = []\n",
    "        prom = 0.06\n",
    "        step = 0.005\n",
    "        # Adjust threshold until we get exactly 25 strokes (or break if not possible)\n",
    "        while not len(strokes) == 25:\n",
    "            strokes = isolator(samples[1 * sample_rate:], sample_rate, 48, 24, 2400, 12000, prom, show=False)\n",
    "            if len(strokes) < 25:\n",
    "                prom -= step\n",
    "            elif len(strokes) > 25:\n",
    "                prom += step\n",
    "            if prom <= 0:\n",
    "                print('-- not possible for:', file)\n",
    "                break\n",
    "            step *= 0.99\n",
    "        \n",
    "        # Apply noise to each extracted stroke\n",
    "        noisy_strokes = [add_noise_to_stroke(stroke, noise_factor) for stroke in strokes]\n",
    "\n",
    "        # Extract a label for this file (modify as needed)\n",
    "        label = extract_label(file)\n",
    "        data_dict['Key'] += [label] * len(noisy_strokes)\n",
    "        data_dict['File'] += noisy_strokes\n",
    "\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    \n",
    "    # Optionally, create a mapping for the labels (if needed)\n",
    "    mapper = {}\n",
    "    counter = 0\n",
    "    for l in df['Key']:\n",
    "        if l not in mapper:\n",
    "            mapper[l] = counter\n",
    "            counter += 1\n",
    "    df.replace({'Key': mapper}, inplace=True)\n",
    "    \n",
    "    return df, sample_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Key                                               File\n",
      "0   0  [[tensor(-11.3724), tensor(8.6698), tensor(5.8...\n",
      "1   0  [[tensor(-15.0360), tensor(5.2527), tensor(9.7...\n",
      "2   0  [[tensor(-4.8263), tensor(-4.3361), tensor(-3....\n",
      "3   0  [[tensor(0.0831), tensor(1.6572), tensor(3.856...\n",
      "4   0  [[tensor(-2.9123), tensor(14.4473), tensor(14....\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Key     900 non-null    object\n",
      " 1   File    900 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 14.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_frame, sr = convert_to_df_with_noise(\"../../dataset/Zoom/\", noise_factor=10)\n",
    "\n",
    "print(data_frame.head())\n",
    "print(data_frame.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 32000\n",
      "630 180 90\n"
     ]
    }
   ],
   "source": [
    "train_set, tmp_set = train_test_split(data_frame, test_size=0.3, stratify=data_frame['Key'])\n",
    "val_set, test_set = train_test_split(tmp_set, test_size=0.33, stratify=tmp_set['Key'])\n",
    "\n",
    "print(\"Sample rate:\", sr)\n",
    "print(len(train_set), len(val_set), len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_name, transform = None, aug = None):\n",
    "        df = file_name\n",
    "        self.transform = transform\n",
    "        self.aug = aug\n",
    "        self.labels = df['Key']\n",
    "        self.values = df['File']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels.iloc[index]\n",
    "        value = self.values.iloc[index]\n",
    "        waveform = self.values.iloc[index]\n",
    "        label = self.labels.iloc[index]\n",
    "        if self.transform:\n",
    "            waveform = waveform.numpy()\n",
    "            waveform = waveform.flatten()\n",
    "            waveform = self.transform(waveform)\n",
    "        if self.aug:\n",
    "            waveform = self.aug(waveform)\n",
    "        return waveform, label\n",
    "\n",
    "class ToMelSpectrogram:\n",
    "    def __call__(self, samples):\n",
    "#         samples = np.array(samples)\n",
    "        spec = librosa.feature.melspectrogram(y = samples, sr = sr, n_mels=64, n_fft=2048, win_length=1024, hop_length=226)\n",
    "        return librosa.power_to_db(spec)\n",
    "\n",
    "class TimeShifting():\n",
    "    def __call__(self, samples):\n",
    "        samples = samples.numpy()\n",
    "        samples = samples.flatten()\n",
    "        \n",
    "        shift = int(len(samples) * 0.4)\n",
    "        random_shift =random.randint(0, shift)\n",
    "        data_roll = np.roll(samples, random_shift)\n",
    "        return data_roll\n",
    "    \n",
    "class SpecAugment():\n",
    "    def __call__(self, samples):\n",
    "        num_mask = 2\n",
    "        freq_masking_max_percentage=0.10\n",
    "        time_masking_max_percentage=0.10\n",
    "        spec = samples.copy()\n",
    "        mean_value = spec.mean()\n",
    "        for i in range(num_mask):\n",
    "            all_frames_num, all_freqs_num = spec.shape[1], spec.shape[1] \n",
    "            freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n",
    "\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            spec[:, f0:f0 + num_freqs_to_mask] = mean_value\n",
    "\n",
    "            time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            spec[t0:t0 + num_frames_to_mask, :] = mean_value\n",
    "        return spec\n",
    "\n",
    "aug = Compose([\n",
    "    TimeShifting(),\n",
    "    ToMelSpectrogram(),\n",
    "    SpecAugment(),\n",
    "    ToTensor()\n",
    "    ])\n",
    "\n",
    "transform = Compose([\n",
    "    ToMelSpectrogram(),\n",
    "    ToTensor()])\n",
    "        \n",
    "train_set = MyDataset(train_set, aug = aug)\n",
    "val_set = MyDataset(val_set, transform = transform)\n",
    "test_set = MyDataset(test_set, transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set image (augmented vs non-augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1.imshow(train_set[0][0][0], cmap='viridis')\n",
    "ax2.imshow(val_set[0][0][0], cmap='viridis')\n",
    "print(train_set[0][0][0].shape)\n",
    "ax1.grid(False)\n",
    "ax2.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 36\n"
     ]
    }
   ],
   "source": [
    "print(\"number of classes:\", len(np.unique(data_frame['Key'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoAtNet (Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stem(nn.Sequential):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__(\n",
    "            nn.Conv2d(1, out_channels, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor=4):\n",
    "        super().__init__()\n",
    "        self.mb_conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.Conv2d(in_channels, in_channels * expansion_factor, kernel_size=1),\n",
    "            nn.BatchNorm2d(in_channels * expansion_factor),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(in_channels * expansion_factor, in_channels * expansion_factor, kernel_size=3, padding=1, groups=in_channels * expansion_factor),\n",
    "            nn.BatchNorm2d(in_channels * expansion_factor),\n",
    "            nn.GELU(),\n",
    "            SqueezeExcitation(in_channels * expansion_factor, in_channels, activation=nn.GELU),\n",
    "            nn.Conv2d(in_channels * expansion_factor, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.mb_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsamplingMBConv(MBConv):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor=4):\n",
    "        super().__init__(in_channels, out_channels, expansion_factor=4)\n",
    "        self.mb_conv[1] = nn.Conv2d(in_channels, in_channels * expansion_factor, kernel_size=1, stride = 2)\n",
    "        self.channel_projection = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.channel_projection(self.pool(x)) + self.mb_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativeAttention2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, image_size, heads=8, head_size=32):\n",
    "        super().__init__()\n",
    "        heads = out_channels // head_size\n",
    "        self.heads = heads\n",
    "        self.head_size = head_size\n",
    "        self.image_size = image_size\n",
    "        self.head_dim = heads * head_size\n",
    "        self.attend = nn.Softmax(dim=-2) # Taken from My_CoAtNet\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.to_q = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_k = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_v = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_output = nn.Sequential(\n",
    "            nn.Linear(self.head_dim, out_channels),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.normalization = nn.LayerNorm(in_channels)\n",
    "        \n",
    "        self.relative_bias = nn.Parameter(torch.randn(heads, (2 * image_size - 1) * (2 * image_size - 1)))\n",
    "        self.register_buffer(\"relative_indices\", self.get_indices(image_size, image_size)) # Taken from My_CoAtNet\n",
    "        self.precomputed_relative_bias = None\n",
    "    \n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "    \n",
    "    def get_relative_biases(self):\n",
    "        # Relative bias caching mentioned in CoAtNet: Marrying Convolution and Attention for All Data Sizes\n",
    "        if not self.training:\n",
    "            return self.precomputed_relative_bias\n",
    "        # Taken from od My_CoAtNet\n",
    "        indices = self.relative_indices.expand(self.heads, -1)\n",
    "        rel_pos_enc = self.relative_bias.gather(-1, indices)\n",
    "        rel_pos_enc = rel_pos_enc.unflatten(-1, (self.image_size * self.image_size, self.image_size * self.image_size))\n",
    "        return rel_pos_enc\n",
    "    \n",
    "    def reshape_for_linear(self, x):\n",
    "        b, _, _, _ = x.shape\n",
    "        return x.reshape(b, self.image_size * self.image_size, self.in_channels)\n",
    "    \n",
    "    def attention_score(self, x):\n",
    "        b, _, h, _ = x.shape\n",
    "        q = self.to_q(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        k = self.to_k(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        dots = torch.matmul(k.transpose(-1, -2), q) / math.sqrt(self.head_dim)\n",
    "        relative_biases_indexed = self.get_relative_biases()\n",
    "        return self.attend(dots + relative_biases_indexed)\n",
    "    \n",
    "    def relative_attention(self, x):\n",
    "        b, _, _, _ = x.shape\n",
    "        v = self.to_v(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        out = torch.matmul(v, self.attention_score(x)) # I figured this out after debugging (Still the same as My_CoAtNet)\n",
    "        out = out.view(b, self.image_size, self.image_size, -1)\n",
    "        return self.to_output(out).view(b, self.out_channels, self.image_size, self.image_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.relative_attention(self.norm(x))\n",
    "    \n",
    "    def train(self, training):\n",
    "        if not training:\n",
    "            self.precomputed_relative_bias = self.get_relative_biases()\n",
    "        super().train(training)\n",
    "        \n",
    "    # Taken from My_CoAtNet\n",
    "    @staticmethod\n",
    "    def get_indices(h, w):\n",
    "        y = torch.arange(h, dtype=torch.long)\n",
    "        x = torch.arange(w, dtype=torch.long)\n",
    "        \n",
    "        y1, x1, y2, x2 = torch.meshgrid(y, x, y, x)\n",
    "        indices = (y1 - y2 + h - 1) * (2 * w - 1) + x1 - x2 + w - 1\n",
    "        indices = indices.flatten()\n",
    "        \n",
    "        return indices\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsamplingRelativeAttention2d(RelativeAttention2d):\n",
    "    def __init__(self, in_channels, out_channels, image_size, heads=8, head_size=32):\n",
    "        super().__init__(in_channels, out_channels, image_size, heads=8, head_size=32)\n",
    "        self.channel_projection = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.normalization = nn.LayerNorm(in_channels)\n",
    "\n",
    "\n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.channel_projection(self.pool(x)) + self.relative_attention(self.pool(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, out_channels, expansion_factor=4):\n",
    "        super().__init__()\n",
    "        hidden_dim = out_channels * expansion_factor\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(out_channels, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, out_channels),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.normalization = nn.LayerNorm(out_channels)\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    \n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        old_shape = x.shape\n",
    "        batch_size = old_shape[0]\n",
    "        return x + torch.reshape(self.ffn(torch.reshape(self.norm(x), (batch_size, -1, self.out_channels))), old_shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleTransformerBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, image_size):\n",
    "        attention = DownsamplingRelativeAttention2d(in_channels, out_channels, image_size)\n",
    "        ffn = FeedForwardNetwork(out_channels)\n",
    "        super().__init__(\n",
    "            attention,\n",
    "            ffn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, image_size):\n",
    "        attention = RelativeAttention2d(in_channels, out_channels, image_size)\n",
    "        ffn = FeedForwardNetwork(out_channels)\n",
    "        super().__init__(\n",
    "            attention,\n",
    "            ffn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(in_channels, num_classes)\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.pool(x)\n",
    "        x = torch.reshape(x, (batch_size, -1, self.in_channels))\n",
    "        return torch.squeeze(self.fc(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCoAtNet(nn.Sequential):\n",
    "    def __init__(self, nums_blocks, layer_out_channels, num_classes=36):\n",
    "        s0 = nn.Sequential(Stem(layer_out_channels[0]))\n",
    "        \n",
    "        s1 = [DownsamplingMBConv(layer_out_channels[0], layer_out_channels[1])]\n",
    "        for i in range(nums_blocks[1] - 1):\n",
    "            s1.append(MBConv(layer_out_channels[1], layer_out_channels[1]))\n",
    "        s1 = nn.Sequential(*s1)\n",
    "        \n",
    "        s2 = [DownsamplingMBConv(layer_out_channels[1], layer_out_channels[2])]\n",
    "        for i in range(nums_blocks[2] - 1):\n",
    "            s2.append(MBConv(layer_out_channels[2], layer_out_channels[2]))\n",
    "        s2 = nn.Sequential(*s2)\n",
    "        \n",
    "        s3 = [DownsampleTransformerBlock(layer_out_channels[2], layer_out_channels[3], 64 // 16)]\n",
    "        for i in range(nums_blocks[3] - 1):\n",
    "            s3.append(TransformerBlock(layer_out_channels[3], layer_out_channels[3], 64 // 16))\n",
    "        s3 = nn.Sequential(*s3)\n",
    "        \n",
    "        s4 = [DownsampleTransformerBlock(layer_out_channels[3], layer_out_channels[4], 64 // 32)]\n",
    "        for i in range(nums_blocks[4] - 1):\n",
    "            s4.append(TransformerBlock(layer_out_channels[4], layer_out_channels[4], 64 // 32))\n",
    "        s4 = nn.Sequential(*s4)\n",
    "        \n",
    "        head = Head(layer_out_channels[4], num_classes)\n",
    "        \n",
    "        super().__init__(\n",
    "            s0,\n",
    "            s1,\n",
    "            s2,\n",
    "            s3,\n",
    "            s4,\n",
    "            head\n",
    "        )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# CoAtNet-1\n",
    "nums_blocks = [2, 2, 3, 5, 2]           # L\n",
    "channels = [64, 96, 192, 384, 768]      # D\n",
    "\n",
    "model = MyCoAtNet(nums_blocks, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_linear(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None: nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 24,033,296\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]             640\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              GELU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 30, 30]          36,928\n",
      "         MaxPool2d-5           [-1, 64, 15, 15]               0\n",
      "            Conv2d-6           [-1, 96, 15, 15]           6,144\n",
      "       BatchNorm2d-7           [-1, 64, 30, 30]             128\n",
      "            Conv2d-8          [-1, 256, 15, 15]          16,640\n",
      "       BatchNorm2d-9          [-1, 256, 15, 15]             512\n",
      "             GELU-10          [-1, 256, 15, 15]               0\n",
      "           Conv2d-11          [-1, 256, 15, 15]           2,560\n",
      "      BatchNorm2d-12          [-1, 256, 15, 15]             512\n",
      "             GELU-13          [-1, 256, 15, 15]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 1, 1]               0\n",
      "           Conv2d-15             [-1, 64, 1, 1]          16,448\n",
      "             GELU-16             [-1, 64, 1, 1]               0\n",
      "           Conv2d-17            [-1, 256, 1, 1]          16,640\n",
      "          Sigmoid-18            [-1, 256, 1, 1]               0\n",
      "SqueezeExcitation-19          [-1, 256, 15, 15]               0\n",
      "           Conv2d-20           [-1, 96, 15, 15]          24,672\n",
      "      BatchNorm2d-21           [-1, 96, 15, 15]             192\n",
      "DownsamplingMBConv-22           [-1, 96, 15, 15]               0\n",
      "      BatchNorm2d-23           [-1, 96, 15, 15]             192\n",
      "           Conv2d-24          [-1, 384, 15, 15]          37,248\n",
      "      BatchNorm2d-25          [-1, 384, 15, 15]             768\n",
      "             GELU-26          [-1, 384, 15, 15]               0\n",
      "           Conv2d-27          [-1, 384, 15, 15]           3,840\n",
      "      BatchNorm2d-28          [-1, 384, 15, 15]             768\n",
      "             GELU-29          [-1, 384, 15, 15]               0\n",
      "AdaptiveAvgPool2d-30            [-1, 384, 1, 1]               0\n",
      "           Conv2d-31             [-1, 96, 1, 1]          36,960\n",
      "             GELU-32             [-1, 96, 1, 1]               0\n",
      "           Conv2d-33            [-1, 384, 1, 1]          37,248\n",
      "          Sigmoid-34            [-1, 384, 1, 1]               0\n",
      "SqueezeExcitation-35          [-1, 384, 15, 15]               0\n",
      "           Conv2d-36           [-1, 96, 15, 15]          36,960\n",
      "      BatchNorm2d-37           [-1, 96, 15, 15]             192\n",
      "           MBConv-38           [-1, 96, 15, 15]               0\n",
      "        MaxPool2d-39             [-1, 96, 8, 8]               0\n",
      "           Conv2d-40            [-1, 192, 8, 8]          18,432\n",
      "      BatchNorm2d-41           [-1, 96, 15, 15]             192\n",
      "           Conv2d-42            [-1, 384, 8, 8]          37,248\n",
      "      BatchNorm2d-43            [-1, 384, 8, 8]             768\n",
      "             GELU-44            [-1, 384, 8, 8]               0\n",
      "           Conv2d-45            [-1, 384, 8, 8]           3,840\n",
      "      BatchNorm2d-46            [-1, 384, 8, 8]             768\n",
      "             GELU-47            [-1, 384, 8, 8]               0\n",
      "AdaptiveAvgPool2d-48            [-1, 384, 1, 1]               0\n",
      "           Conv2d-49             [-1, 96, 1, 1]          36,960\n",
      "             GELU-50             [-1, 96, 1, 1]               0\n",
      "           Conv2d-51            [-1, 384, 1, 1]          37,248\n",
      "          Sigmoid-52            [-1, 384, 1, 1]               0\n",
      "SqueezeExcitation-53            [-1, 384, 8, 8]               0\n",
      "           Conv2d-54            [-1, 192, 8, 8]          73,920\n",
      "      BatchNorm2d-55            [-1, 192, 8, 8]             384\n",
      "DownsamplingMBConv-56            [-1, 192, 8, 8]               0\n",
      "      BatchNorm2d-57            [-1, 192, 8, 8]             384\n",
      "           Conv2d-58            [-1, 768, 8, 8]         148,224\n",
      "      BatchNorm2d-59            [-1, 768, 8, 8]           1,536\n",
      "             GELU-60            [-1, 768, 8, 8]               0\n",
      "           Conv2d-61            [-1, 768, 8, 8]           7,680\n",
      "      BatchNorm2d-62            [-1, 768, 8, 8]           1,536\n",
      "             GELU-63            [-1, 768, 8, 8]               0\n",
      "AdaptiveAvgPool2d-64            [-1, 768, 1, 1]               0\n",
      "           Conv2d-65            [-1, 192, 1, 1]         147,648\n",
      "             GELU-66            [-1, 192, 1, 1]               0\n",
      "           Conv2d-67            [-1, 768, 1, 1]         148,224\n",
      "          Sigmoid-68            [-1, 768, 1, 1]               0\n",
      "SqueezeExcitation-69            [-1, 768, 8, 8]               0\n",
      "           Conv2d-70            [-1, 192, 8, 8]         147,648\n",
      "      BatchNorm2d-71            [-1, 192, 8, 8]             384\n",
      "           MBConv-72            [-1, 192, 8, 8]               0\n",
      "      BatchNorm2d-73            [-1, 192, 8, 8]             384\n",
      "           Conv2d-74            [-1, 768, 8, 8]         148,224\n",
      "      BatchNorm2d-75            [-1, 768, 8, 8]           1,536\n",
      "             GELU-76            [-1, 768, 8, 8]               0\n",
      "           Conv2d-77            [-1, 768, 8, 8]           7,680\n",
      "      BatchNorm2d-78            [-1, 768, 8, 8]           1,536\n",
      "             GELU-79            [-1, 768, 8, 8]               0\n",
      "AdaptiveAvgPool2d-80            [-1, 768, 1, 1]               0\n",
      "           Conv2d-81            [-1, 192, 1, 1]         147,648\n",
      "             GELU-82            [-1, 192, 1, 1]               0\n",
      "           Conv2d-83            [-1, 768, 1, 1]         148,224\n",
      "          Sigmoid-84            [-1, 768, 1, 1]               0\n",
      "SqueezeExcitation-85            [-1, 768, 8, 8]               0\n",
      "           Conv2d-86            [-1, 192, 8, 8]         147,648\n",
      "      BatchNorm2d-87            [-1, 192, 8, 8]             384\n",
      "           MBConv-88            [-1, 192, 8, 8]               0\n",
      "        MaxPool2d-89            [-1, 192, 4, 4]               0\n",
      "           Conv2d-90            [-1, 384, 4, 4]          73,728\n",
      "        LayerNorm-91            [-1, 8, 8, 192]             384\n",
      "        MaxPool2d-92            [-1, 192, 4, 4]               0\n",
      "           Linear-93              [-1, 16, 384]          74,112\n",
      "           Linear-94              [-1, 16, 384]          74,112\n",
      "           Linear-95              [-1, 16, 384]          74,112\n",
      "          Softmax-96           [-1, 12, 16, 16]               0\n",
      "           Linear-97            [-1, 4, 4, 384]         147,840\n",
      "          Dropout-98            [-1, 4, 4, 384]               0\n",
      "DownsamplingRelativeAttention2d-99            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-100            [-1, 4, 4, 384]             768\n",
      "          Linear-101             [-1, 16, 1536]         591,360\n",
      "            GELU-102             [-1, 16, 1536]               0\n",
      "         Dropout-103             [-1, 16, 1536]               0\n",
      "          Linear-104              [-1, 16, 384]         590,208\n",
      "         Dropout-105              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-106            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-107            [-1, 4, 4, 384]             768\n",
      "          Linear-108              [-1, 16, 384]         147,840\n",
      "          Linear-109              [-1, 16, 384]         147,840\n",
      "          Linear-110              [-1, 16, 384]         147,840\n",
      "         Softmax-111           [-1, 12, 16, 16]               0\n",
      "          Linear-112            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-113            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-114            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-115            [-1, 4, 4, 384]             768\n",
      "          Linear-116             [-1, 16, 1536]         591,360\n",
      "            GELU-117             [-1, 16, 1536]               0\n",
      "         Dropout-118             [-1, 16, 1536]               0\n",
      "          Linear-119              [-1, 16, 384]         590,208\n",
      "         Dropout-120              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-121            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-122            [-1, 4, 4, 384]             768\n",
      "          Linear-123              [-1, 16, 384]         147,840\n",
      "          Linear-124              [-1, 16, 384]         147,840\n",
      "          Linear-125              [-1, 16, 384]         147,840\n",
      "         Softmax-126           [-1, 12, 16, 16]               0\n",
      "          Linear-127            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-128            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-129            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-130            [-1, 4, 4, 384]             768\n",
      "          Linear-131             [-1, 16, 1536]         591,360\n",
      "            GELU-132             [-1, 16, 1536]               0\n",
      "         Dropout-133             [-1, 16, 1536]               0\n",
      "          Linear-134              [-1, 16, 384]         590,208\n",
      "         Dropout-135              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-136            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-137            [-1, 4, 4, 384]             768\n",
      "          Linear-138              [-1, 16, 384]         147,840\n",
      "          Linear-139              [-1, 16, 384]         147,840\n",
      "          Linear-140              [-1, 16, 384]         147,840\n",
      "         Softmax-141           [-1, 12, 16, 16]               0\n",
      "          Linear-142            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-143            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-144            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-145            [-1, 4, 4, 384]             768\n",
      "          Linear-146             [-1, 16, 1536]         591,360\n",
      "            GELU-147             [-1, 16, 1536]               0\n",
      "         Dropout-148             [-1, 16, 1536]               0\n",
      "          Linear-149              [-1, 16, 384]         590,208\n",
      "         Dropout-150              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-151            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-152            [-1, 4, 4, 384]             768\n",
      "          Linear-153              [-1, 16, 384]         147,840\n",
      "          Linear-154              [-1, 16, 384]         147,840\n",
      "          Linear-155              [-1, 16, 384]         147,840\n",
      "         Softmax-156           [-1, 12, 16, 16]               0\n",
      "          Linear-157            [-1, 4, 4, 384]         147,840\n",
      "         Dropout-158            [-1, 4, 4, 384]               0\n",
      "RelativeAttention2d-159            [-1, 384, 4, 4]               0\n",
      "       LayerNorm-160            [-1, 4, 4, 384]             768\n",
      "          Linear-161             [-1, 16, 1536]         591,360\n",
      "            GELU-162             [-1, 16, 1536]               0\n",
      "         Dropout-163             [-1, 16, 1536]               0\n",
      "          Linear-164              [-1, 16, 384]         590,208\n",
      "         Dropout-165              [-1, 16, 384]               0\n",
      "FeedForwardNetwork-166            [-1, 384, 4, 4]               0\n",
      "       MaxPool2d-167            [-1, 384, 2, 2]               0\n",
      "          Conv2d-168            [-1, 768, 2, 2]         294,912\n",
      "       LayerNorm-169            [-1, 4, 4, 384]             768\n",
      "       MaxPool2d-170            [-1, 384, 2, 2]               0\n",
      "          Linear-171               [-1, 4, 768]         295,680\n",
      "          Linear-172               [-1, 4, 768]         295,680\n",
      "          Linear-173               [-1, 4, 768]         295,680\n",
      "         Softmax-174             [-1, 24, 4, 4]               0\n",
      "          Linear-175            [-1, 2, 2, 768]         590,592\n",
      "         Dropout-176            [-1, 2, 2, 768]               0\n",
      "DownsamplingRelativeAttention2d-177            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-178            [-1, 2, 2, 768]           1,536\n",
      "          Linear-179              [-1, 4, 3072]       2,362,368\n",
      "            GELU-180              [-1, 4, 3072]               0\n",
      "         Dropout-181              [-1, 4, 3072]               0\n",
      "          Linear-182               [-1, 4, 768]       2,360,064\n",
      "         Dropout-183               [-1, 4, 768]               0\n",
      "FeedForwardNetwork-184            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-185            [-1, 2, 2, 768]           1,536\n",
      "          Linear-186               [-1, 4, 768]         590,592\n",
      "          Linear-187               [-1, 4, 768]         590,592\n",
      "          Linear-188               [-1, 4, 768]         590,592\n",
      "         Softmax-189             [-1, 24, 4, 4]               0\n",
      "          Linear-190            [-1, 2, 2, 768]         590,592\n",
      "         Dropout-191            [-1, 2, 2, 768]               0\n",
      "RelativeAttention2d-192            [-1, 768, 2, 2]               0\n",
      "       LayerNorm-193            [-1, 2, 2, 768]           1,536\n",
      "          Linear-194              [-1, 4, 3072]       2,362,368\n",
      "            GELU-195              [-1, 4, 3072]               0\n",
      "         Dropout-196              [-1, 4, 3072]               0\n",
      "          Linear-197               [-1, 4, 768]       2,360,064\n",
      "         Dropout-198               [-1, 4, 768]               0\n",
      "FeedForwardNetwork-199            [-1, 768, 2, 2]               0\n",
      "AdaptiveAvgPool2d-200            [-1, 768, 1, 1]               0\n",
      "          Linear-201                [-1, 1, 36]          27,684\n",
      "            Head-202                   [-1, 36]               0\n",
      "================================================================\n",
      "Total params: 24,029,924\n",
      "Trainable params: 24,029,924\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 26.27\n",
      "Params size (MB): 91.67\n",
      "Estimated Total Size (MB): 117.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.apply(init_linear)\n",
    "model.to(device)\n",
    "\n",
    "print(\"Number of parameters: {:,}\".format(sum(p.numel() for p in model.parameters())))\n",
    "\n",
    "summary(model, input_size=(1, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyCoAtNet(\n",
       "  (0): Sequential(\n",
       "    (0): Stem(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Head(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=768, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.load_state_dict(torch.load(\"CoAtNet-1-Best-Zoom.pkl\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from My_CoAtNet\n",
    "def separate_parameters(model):\n",
    "    parameters_decay = set()\n",
    "    parameters_no_decay = set()\n",
    "    modules_weight_decay = (nn.Linear, nn.Conv2d)\n",
    "    modules_no_weight_decay = (nn.LayerNorm, nn.BatchNorm2d)\n",
    "    \n",
    "    for m_name, m in model.named_modules():\n",
    "        for param_name, param in m.named_parameters():\n",
    "            full_param_name = f\"{m_name}.{param_name}\" if m_name else param_name\n",
    "\n",
    "            if isinstance(m, modules_no_weight_decay):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif param_name.endswith(\"bias\"):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif isinstance(m, modules_weight_decay):\n",
    "                parameters_decay.add(full_param_name)\n",
    "    \n",
    "    # sanity check\n",
    "    assert len(parameters_decay & parameters_no_decay) == 0\n",
    "    assert len(parameters_decay) + len(parameters_no_decay) == len(list(model.parameters()))\n",
    "\n",
    "    return parameters_decay, parameters_no_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 5e-4\n",
    "weight_decay = 0.1\n",
    "num_epochs = 1100\n",
    "min_learning_rate = 1e-6\n",
    "\n",
    "param_dict = {pn: p for pn, p in model.named_parameters()}\n",
    "parameters_decay, parameters_no_decay = separate_parameters(model)\n",
    "parameter_groups = [\n",
    "    {\"params\": [param_dict[pn] for pn in parameters_decay], \"weight_decay\": weight_decay},\n",
    "    {\"params\": [param_dict[pn] for pn in parameters_no_decay], \"weight_decay\": 0.0},\n",
    "]\n",
    "optimizer = torch.optim.Adam(parameter_groups, lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=min_learning_rate / learning_rate, total_iters=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from My_CoAtNet\n",
    "def plot_results(train_losses, train_accuracies, val_losses, val_accuracies):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.legend([\"Training loss\", \"Validation loss\"], loc =  \"best\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(train_accuracies)\n",
    "    plt.plot(val_accuracies)\n",
    "    plt.legend([\"Training accuracy\", \"Validation accuracy\"], loc =  \"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"CoAtNet-1-Best-Zoom.pkl\"\n",
    "model_path = \"CoAtNet-1-Zoom.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyCoAtNet(\n",
       "  (0): Sequential(\n",
       "    (0): Stem(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Head(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=768, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings from indices to syllables and vice versa\n",
    "digits_and_syllables = list('0123456789abcdefghijklmnopqrstuvwxyz')\n",
    "idx_to_syllable = {idx: syllable for idx, syllable in enumerate(digits_and_syllables)}\n",
    "syllable_to_idx = {syllable: idx for idx, syllable in idx_to_syllable.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine test and validation datasets\n",
    "combined_dataset = ConcatDataset([val_set, test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from syllables to dataset indices\n",
    "syllable_to_indices = {}\n",
    "for idx in range(len(combined_dataset)):\n",
    "    _, label = combined_dataset[idx]\n",
    "    # label = label.item() \n",
    "    syllable = idx_to_syllable[label]\n",
    "    if syllable not in syllable_to_indices:\n",
    "        syllable_to_indices[syllable] = []\n",
    "    syllable_to_indices[syllable].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process sentences into syllables\n",
    "def get_syllables(sentence):\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    # sentence = sentence.replace(' ',  '').lower()\n",
    "    syllables = list(sentence)\n",
    "    return syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 1000\n"
     ]
    }
   ],
   "source": [
    "# Read sentences from the text file\n",
    "with open('../sentences/sentences.txt', 'r') as f:\n",
    "    sentences = f.readlines()\n",
    "\n",
    "print(\"Number of sentences:\", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence):\n",
    "    # Character-level accuracy using SequenceMatcher\n",
    "    char_matcher = difflib.SequenceMatcher(None, true_sentence, predicted_sentence)\n",
    "    accuracy = char_matcher.ratio()\n",
    "    \n",
    "    # Word-level wrong syllable count using SequenceMatcher on word lists\n",
    "    true_words = true_sentence.split()\n",
    "    predicted_words = predicted_sentence.split()\n",
    "    word_matcher = difflib.SequenceMatcher(None, true_words, predicted_words)\n",
    "    \n",
    "    # Calculate wrong syllables based on insert, delete, and replace operations\n",
    "    wrong_syllables = sum(1 for tag, _, _, _, _ in word_matcher.get_opcodes() if tag in ('insert', 'delete', 'replace'))\n",
    "    \n",
    "    return accuracy, wrong_syllables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "# Process each sentence\n",
    "noise_factor = 0\n",
    "results = []\n",
    "\n",
    "for sentence in tqdm(sentences[:10]):\n",
    "    sentence = sentence.strip()\n",
    "    syllables = get_syllables(sentence)\n",
    "    true_sentence = ''.join(syllables)\n",
    "    predicted_syllables = []\n",
    "\n",
    "    for syllable in syllables:\n",
    "        if syllable in syllable_to_indices:\n",
    "            # Randomly select an index for the syllable\n",
    "            idx = random.choice(syllable_to_indices[syllable])\n",
    "            # Retrieve the image and label from the dataset\n",
    "            image, _ = combined_dataset[idx]\n",
    "\n",
    "            noise = torch.randn_like(image) * noise_factor\n",
    "            image = image + noise\n",
    "            image = image.unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "                output = output.reshape(1, -1)\n",
    "                _, predicted_idx = torch.max(output.data, 1)\n",
    "                predicted_syllable = idx_to_syllable[predicted_idx.item()]\n",
    "        else:\n",
    "            if random.random() < 0.90:\n",
    "                predicted_syllable = ' '\n",
    "            else:\n",
    "                predicted_syllable = random.choice(digits_and_syllables)\n",
    "        predicted_syllables.append(predicted_syllable)\n",
    "    \n",
    "    predicted_sentence = ''.join(predicted_syllables)\n",
    "    accuracy, wrong_syllables = compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence)\n",
    "    results.append([true_sentence, predicted_sentence, accuracy, wrong_syllables])\n",
    "    # print(f\"accuracy: {accuracy}, wrong: {wrong_syllables}, true: {true_sentence}, predicted: {predicted_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise factor: 0\n",
      "Average accuracy: 0.1108\n",
      "Total wrong syllables: 10\n"
     ]
    }
   ],
   "source": [
    "# accuracy average and wrong syllables sum\n",
    "accuracy_avg = sum(result[2] for result in results) / len(results)\n",
    "wrong_syllables_sum = sum(result[3] for result in results)\n",
    "\n",
    "print(\"Noise factor:\", noise_factor)\n",
    "print(f\"Average accuracy: {accuracy_avg:.4f}\")\n",
    "print(f\"Total wrong syllables: {wrong_syllables_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/{noise_factor}.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['True Sentence', 'Predicted Sentence', 'Accuracy', 'Wrong syllables'])\n",
    "    for row in results:\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
