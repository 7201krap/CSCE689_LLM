{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import difflib\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"input_batches\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messages(sentence, examples):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in correcting typos in sentences.\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "Here are examples of sentences with typos; learn from them:\n",
    "\n",
    "{examples}\n",
    "Now, please correct this sentence and output only the corrected version with no additional text:\n",
    "\n",
    "{target_sentence}\n",
    "        \"\"\".format(target_sentence=sentence, examples=examples)},\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2816753/1033020455.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for index, row in tqdm(df.iterrows(), total=total):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e0f9e6218e4a338894b953ffceb02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved input_batches/phone_gpt4o_nf_noise_0.012.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2816753/1033020455.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for index, row in tqdm(df.iterrows(), total=total):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a94fe278c674979a21dad990c25007e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved input_batches/phone_gpt4o_nf_noise_0.024.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2816753/1033020455.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for index, row in tqdm(df.iterrows(), total=total):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c47babd70b4652964ea82c0abe84f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved input_batches/phone_gpt4o_nf_noise_0.06.jsonl\n"
     ]
    }
   ],
   "source": [
    "# create input batches (jsonl)\n",
    "\n",
    "NFs = [\n",
    "    \"noise_0.1\",\n",
    "    \"noise_0.5\",\n",
    "    \"noise_1.0\",\n",
    "]\n",
    "\n",
    "for nf in NFs:\n",
    "    df = pd.read_csv(f\"results/{nf}.csv\")\n",
    "    examples = \"\"\n",
    "    total=len(df)\n",
    "    jsonl_file = f\"input_batches/zoom_gpt4o_nf_{nf}.jsonl\"\n",
    "    jsonl = []\n",
    "\n",
    "    for i in range(2):\n",
    "        examples += f\"\\tsentence: {df['Predicted Sentence'][i]}\\n\"\n",
    "        examples += f\"\\tcorrected: {df['True Sentence'][i]}\\n\\n\"\n",
    "        \n",
    "    for index, row in tqdm(df.iterrows(), total=total):\n",
    "        predicted_sentence = row['Predicted Sentence']\n",
    "        messages = get_messages(predicted_sentence, examples)\n",
    "        # create openai request\n",
    "        prompt = {\n",
    "            \"custom_id\": f\"{index}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": \"gpt-4o\",\n",
    "                \"messages\": messages,\n",
    "                \"max_tokens\": 1000,\n",
    "            }\n",
    "        }\n",
    "        jsonl.append(json.dumps(prompt))\n",
    "    \n",
    "    with open(jsonl_file, \"w\") as f:\n",
    "        for line in jsonl:\n",
    "            f.write(line + \"\\n\")\n",
    "    print(f\"Saved {jsonl_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_openai_batch_output(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        responses = [json.loads(line) for line in file]\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_sentence_from_openai(responses, index):\n",
    "    # Find the response corresponding to the current index\n",
    "    response = responses[index]\n",
    "    llm_sentence = response['response']['body']['choices'][0]['message']['content']\n",
    "    return llm_sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_postprocess(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    # remove all non a-z0-9 \n",
    "    sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence):\n",
    "    # Character-level accuracy using SequenceMatcher\n",
    "    char_matcher = difflib.SequenceMatcher(None, true_sentence, predicted_sentence)\n",
    "    accuracy = char_matcher.ratio()\n",
    "    \n",
    "    # Word-level wrong syllable count using SequenceMatcher on word lists\n",
    "    true_words = true_sentence.split()\n",
    "    predicted_words = predicted_sentence.split()\n",
    "    word_matcher = difflib.SequenceMatcher(None, true_words, predicted_words)\n",
    "    \n",
    "    # Calculate wrong syllables based on insert, delete, and replace operations\n",
    "    wrong_syllables = sum(1 for tag, _, _, _, _ in word_matcher.get_opcodes() if tag in ('insert', 'delete', 'replace'))\n",
    "    \n",
    "    return accuracy, wrong_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3151365/1726385748.py:26: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for index, row in tqdm(df.iterrows(), total=total):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "045129c88f4a46f5ac4d280ab060c3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LLM Auto] Index: 0 of 1000\n",
      "[LLM Auto] CoAtNet 0.9423076923076923 4\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 100 of 1000\n",
      "[LLM Auto] CoAtNet 0.958904109589041 2\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 200 of 1000\n",
      "[LLM Auto] CoAtNet 0.9404761904761905 3\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 300 of 1000\n",
      "[LLM Auto] CoAtNet 0.9594594594594594 3\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 400 of 1000\n",
      "[LLM Auto] CoAtNet 0.9166666666666666 4\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 500 of 1000\n",
      "[LLM Auto] CoAtNet 0.9365079365079365 2\n",
      "[LLM Auto] LLM 0.8571428571428571 3\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 600 of 1000\n",
      "[LLM Auto] CoAtNet 0.9358974358974359 3\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 700 of 1000\n",
      "[LLM Auto] CoAtNet 0.9468085106382979 4\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 800 of 1000\n",
      "[LLM Auto] CoAtNet 0.9418604651162791 3\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 900 of 1000\n",
      "[LLM Auto] CoAtNet 0.9888888888888889 1\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Model: GPT-4o\n",
      "[LLM Auto] NF noise_0.1\n",
      "[LLM Auto] LLM Average Accuracy: 0.9979707707758716\n",
      "[LLM Auto] LLM Sum of Wrong Syllables: 141\n",
      "[LLM Auto] ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3151365/1726385748.py:26: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for index, row in tqdm(df.iterrows(), total=total):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8692d2ddc9af4f639ecbe51f4e9ade72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LLM Auto] Index: 0 of 1000\n",
      "[LLM Auto] CoAtNet 0.8269230769230769 3\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 100 of 1000\n",
      "[LLM Auto] CoAtNet 0.7945205479452054 4\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 200 of 1000\n",
      "[LLM Auto] CoAtNet 0.7857142857142857 3\n",
      "[LLM Auto] LLM 0.9704142011834319 1\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 300 of 1000\n",
      "[LLM Auto] CoAtNet 0.8648648648648649 4\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 400 of 1000\n",
      "[LLM Auto] CoAtNet 0.8333333333333334 3\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 500 of 1000\n",
      "[LLM Auto] CoAtNet 0.873015873015873 4\n",
      "[LLM Auto] LLM 0.9682539682539683 1\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 600 of 1000\n",
      "[LLM Auto] CoAtNet 0.7051282051282052 1\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 700 of 1000\n",
      "[LLM Auto] CoAtNet 0.7872340425531915 4\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 800 of 1000\n",
      "[LLM Auto] CoAtNet 0.7325581395348837 2\n",
      "[LLM Auto] LLM 0.9651162790697675 1\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 900 of 1000\n",
      "[LLM Auto] CoAtNet 0.7888888888888889 2\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Model: GPT-4o\n",
      "[LLM Auto] NF noise_0.5\n",
      "[LLM Auto] LLM Average Accuracy: 0.984046797738791\n",
      "[LLM Auto] LLM Sum of Wrong Syllables: 526\n",
      "[LLM Auto] ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3151365/1726385748.py:26: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for index, row in tqdm(df.iterrows(), total=total):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add28444e40a48e6b9499e700ce4921a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LLM Auto] Index: 0 of 1000\n",
      "[LLM Auto] CoAtNet 0.625 1\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 100 of 1000\n",
      "[LLM Auto] CoAtNet 0.6712328767123288 3\n",
      "[LLM Auto] LLM 0.684931506849315 1\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 200 of 1000\n",
      "[LLM Auto] CoAtNet 0.5714285714285714 2\n",
      "[LLM Auto] LLM 0.8383233532934131 1\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 300 of 1000\n",
      "[LLM Auto] CoAtNet 0.5135135135135135 1\n",
      "[LLM Auto] LLM 0.6410256410256411 2\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 400 of 1000\n",
      "[LLM Auto] CoAtNet 0.5833333333333334 3\n",
      "[LLM Auto] LLM 0.9722222222222222 1\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 500 of 1000\n",
      "[LLM Auto] CoAtNet 0.7777777777777778 5\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 600 of 1000\n",
      "[LLM Auto] CoAtNet 0.6923076923076923 1\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 700 of 1000\n",
      "[LLM Auto] CoAtNet 0.6808510638297872 2\n",
      "[LLM Auto] LLM 0.9166666666666666 1\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 800 of 1000\n",
      "[LLM Auto] CoAtNet 0.813953488372093 2\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 900 of 1000\n",
      "[LLM Auto] CoAtNet 0.6333333333333333 1\n",
      "[LLM Auto] LLM 0.8045977011494253 1\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Model: GPT-4o\n",
      "[LLM Auto] NF noise_1.0\n",
      "[LLM Auto] LLM Average Accuracy: 0.8592095180195036\n",
      "[LLM Auto] LLM Sum of Wrong Syllables: 1737\n",
      "[LLM Auto] ===\n"
     ]
    }
   ],
   "source": [
    "# prepare the output batches\n",
    "output_batches_dir = \"output_batches\"\n",
    "name_prefix = \"zoom_gpt4o_nf_\"\n",
    "output_dir = \"results/gpt-4o\"\n",
    "NFs = [\n",
    "    \"noise_0.1\",\n",
    "    \"noise_0.5\",\n",
    "    \"noise_1.0\",\n",
    "]\n",
    "\n",
    "\n",
    "for nf in NFs:\n",
    "    df = pd.read_csv(f\"results/{nf}.csv\")\n",
    "    responses = load_openai_batch_output(f'{output_batches_dir}/{name_prefix}{nf}.jsonl')\n",
    "    examples = \"\"\n",
    "\n",
    "    for i in range(2):\n",
    "        examples += f\"\\tsentence: {df['Predicted Sentence'][i]}\\n\"\n",
    "        examples += f\"\\tcorrected: {df['True Sentence'][i]}\\n\\n\"\n",
    "\n",
    "    llm_accs = []\n",
    "    llm_ws = []\n",
    "    llm_sen = []\n",
    "    total = len(df)\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=total):\n",
    "        should_print = index % 100 == 0\n",
    "        predicted_sentence = row['Predicted Sentence']\n",
    "        true_sentence = row['True Sentence']\n",
    "        accuracy, wrong_syllables = compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence)\n",
    "        \n",
    "        if should_print:\n",
    "            print(f\"[LLM Auto] Index: {index} of {total}\")\n",
    "            print(\"[LLM Auto] CoAtNet\", accuracy, wrong_syllables)\n",
    "\n",
    "        llm_sentence = get_llm_sentence_from_openai(responses, index)\n",
    "        llm_sentence = llm_postprocess(llm_sentence)\n",
    "        accuracy, wrong_syllables = compute_accuracy_and_wrong_syllables(true_sentence, llm_sentence)\n",
    "        \n",
    "        if should_print:\n",
    "            print(\"[LLM Auto] LLM\", accuracy, wrong_syllables)\n",
    "            print(\"[LLM Auto] ==========\")\n",
    "        \n",
    "        llm_sen.append(llm_sentence)\n",
    "        llm_accs.append(accuracy)\n",
    "        llm_ws.append(wrong_syllables)\n",
    "\n",
    "    df['LLM Sentence'] = llm_sen\n",
    "    df['LLM Accuracy'] = llm_accs\n",
    "    df['LLM Wrong syllables'] = llm_ws\n",
    "\n",
    "    llm_avg_accuracy = sum(llm_accs) / len(llm_accs)\n",
    "    llm_sum_wrong_syllables = sum(llm_ws)\n",
    "\n",
    "    print(f\"[LLM Auto] Model: GPT-4o\")\n",
    "    print(f\"[LLM Auto] NF {nf}\")\n",
    "    print(f\"[LLM Auto] LLM Average Accuracy: {llm_avg_accuracy}\")\n",
    "    print(f\"[LLM Auto] LLM Sum of Wrong Syllables: {llm_sum_wrong_syllables}\")\n",
    "    print(\"[LLM Auto] ===\")\n",
    "    \n",
    "    df.to_csv(f'{output_dir}/{nf}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
