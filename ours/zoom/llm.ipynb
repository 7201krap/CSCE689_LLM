{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf1037b-b3f1-476d-9b25-435f99d4250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5b39ba4-2671-47ba-aec8-4f96bc9a5091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seyyedaliayati\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli whoami              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49b9bbb5-f5e0-4c33-8ed1-21b99bf247a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4511ae51-a286-4be8-8f78-fa01c31eee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tresults_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42636cd0-35aa-48ba-a401-539cf39edbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Sentence</th>\n",
       "      <th>Predicted Sentence</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Wrong syllables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the government will be investing in infrastruc...</td>\n",
       "      <td>the?government?will?be?investing?in?infrastruc...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cosmologists will be studying the evolution of...</td>\n",
       "      <td>xosmologists?will?be?studying?the?evolution?of...</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>predictive analytics will drive the developmen...</td>\n",
       "      <td>predictive?amalytics?will?drive?the?denelopmen...</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fashion houses have embraced the use of sustai...</td>\n",
       "      <td>fashionwhouses?have?embraced?the?use?of?sustai...</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they were rearended by a distracted driver</td>\n",
       "      <td>they?were?rearended?by?a?distracted?driver</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tomorrow i will be teaching a new lesson on ma...</td>\n",
       "      <td>tomorrow?i?will?ne?geaching?a?new?lesson?on?ma...</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>bangladeshi culture will be celebrated worldwide</td>\n",
       "      <td>bamgladeshi?culture?will?be?celebrated?worldwide</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>the achievements of women in stem have fostere...</td>\n",
       "      <td>thelachievements?of?women?in?stemfhave?fostere...</td>\n",
       "      <td>0.958763</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>over the past decade women have contributed to...</td>\n",
       "      <td>over?the?past?decade?women?have?contrinuted?to...</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>she traveled to japan and immersed herself in ...</td>\n",
       "      <td>she?traveled?to?japan?and?immersed?herself?in?...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        True Sentence  \\\n",
       "0   the government will be investing in infrastruc...   \n",
       "1   cosmologists will be studying the evolution of...   \n",
       "2   predictive analytics will drive the developmen...   \n",
       "3   fashion houses have embraced the use of sustai...   \n",
       "4          they were rearended by a distracted driver   \n",
       "..                                                ...   \n",
       "95  tomorrow i will be teaching a new lesson on ma...   \n",
       "96   bangladeshi culture will be celebrated worldwide   \n",
       "97  the achievements of women in stem have fostere...   \n",
       "98  over the past decade women have contributed to...   \n",
       "99  she traveled to japan and immersed herself in ...   \n",
       "\n",
       "                                   Predicted Sentence  Accuracy  \\\n",
       "0   the?government?will?be?investing?in?infrastruc...  1.000000   \n",
       "1   xosmologists?will?be?studying?the?evolution?of...  0.987179   \n",
       "2   predictive?amalytics?will?drive?the?denelopmen...  0.974359   \n",
       "3   fashionwhouses?have?embraced?the?use?of?sustai...  0.987952   \n",
       "4          they?were?rearended?by?a?distracted?driver  1.000000   \n",
       "..                                                ...       ...   \n",
       "95  tomorrow?i?will?ne?geaching?a?new?lesson?on?ma...  0.963636   \n",
       "96   bamgladeshi?culture?will?be?celebrated?worldwide  0.979167   \n",
       "97  thelachievements?of?women?in?stemfhave?fostere...  0.958763   \n",
       "98  over?the?past?decade?women?have?contrinuted?to...  0.981481   \n",
       "99  she?traveled?to?japan?and?immersed?herself?in?...  1.000000   \n",
       "\n",
       "    Wrong syllables  \n",
       "0                 0  \n",
       "1                 1  \n",
       "2                 2  \n",
       "3                 1  \n",
       "4                 0  \n",
       "..              ...  \n",
       "95                2  \n",
       "96                1  \n",
       "97                4  \n",
       "98                2  \n",
       "99                0  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "618dc25e-4062-48a9-8856-dcce44e19d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a41d06313a459fa1c6516e5d02531a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0b2d7e0-8c31-45c5-82ef-47a60fb57704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messages(sentence):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in correcting typos and adding missing spaces in sentences.\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "Here are examples of sentences with '?' char instead of space and with some typos; learn from them:\n",
    "\n",
    "    sentence: we?visited?a?botanical?garden?and?admired?the?exotic?plants\n",
    "    corrected: we visited a botanical garden and admired the exotic plants\n",
    "    \n",
    "    sentence: bangladeshi?traders?embrace?ecommerxe?platforms\n",
    "    corrected: bangladeshi traders embrace ecommerce platforms\n",
    "\n",
    "Now, please correct this sentence and output only the corrected version with no additional text:\n",
    "    \n",
    "{target_sentence}\n",
    "        \"\"\".format(target_sentence=sentence)},\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b8d70dc-67c6-48dd-937b-210ee2a4cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_sentence(sentence):\n",
    "    messages = get_messages(sentence)\n",
    "    outputs = pipe(\n",
    "        messages,\n",
    "        max_new_tokens=256,\n",
    "    )\n",
    "    llm_sentence = outputs[0][\"generated_text\"][-1][\"content\"]\n",
    "    return llm_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c4a1fb0-2b1f-4b8a-918b-0c977d26b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_postprocess(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    # remove all non a-z0-9 \n",
    "    sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98936f58-17fa-424b-839c-9d421a3253f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence):\n",
    "    # Character-level accuracy using SequenceMatcher\n",
    "    char_matcher = difflib.SequenceMatcher(None, true_sentence, predicted_sentence)\n",
    "    accuracy = char_matcher.ratio()\n",
    "    \n",
    "    # Word-level wrong syllable count using SequenceMatcher on word lists\n",
    "    true_words = true_sentence.split()\n",
    "    predicted_words = predicted_sentence.split()\n",
    "    word_matcher = difflib.SequenceMatcher(None, true_words, predicted_words)\n",
    "    \n",
    "    # Calculate wrong syllables based on insert, delete, and replace operations\n",
    "    wrong_syllables = sum(1 for tag, _, _, _, _ in word_matcher.get_opcodes() if tag in ('insert', 'delete', 'replace'))\n",
    "    \n",
    "    return accuracy, wrong_syllables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a9ca5a8-497e-4c9a-b77f-29350c26de66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "c:\\Users\\seyyedaliayati\\AppData\\Local\\anaconda3\\envs\\rosa\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:602: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8709677419354839 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8589743589743589 1\n",
      "LLM 0.9871794871794872 1\n",
      "==========\n",
      "Index: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8717948717948718 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8674698795180723 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8571428571428571 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8507462686567164 1\n",
      "LLM 0.9701492537313433 1\n",
      "==========\n",
      "Index: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8603351955307262 1\n",
      "LLM 0.9829545454545454 1\n",
      "==========\n",
      "Index: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8382352941176471 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8987341772151899 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8571428571428571 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8604651162790697 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8536585365853658 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8641975308641975 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8461538461538461 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8589743589743589 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8588235294117647 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8736842105263158 1\n",
      "LLM 0.9894736842105263 2\n",
      "==========\n",
      "Index: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8208955223880597 1\n",
      "LLM 0.9850746268656716 1\n",
      "==========\n",
      "Index: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.819672131147541 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8356164383561644 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8666666666666667 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8518518518518519 1\n",
      "LLM 0.9876543209876543 1\n",
      "==========\n",
      "Index: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.868421052631579 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.875 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8429752066115702 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.868421052631579 1\n",
      "LLM 0.987012987012987 1\n",
      "==========\n",
      "Index: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8658536585365854 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8604651162790697 1\n",
      "LLM 0.9285714285714286 1\n",
      "==========\n",
      "Index: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.810126582278481 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8356164383561644 1\n",
      "LLM 0.9726027397260274 1\n",
      "==========\n",
      "Index: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8936170212765957 1\n",
      "LLM 0.9690721649484536 1\n",
      "==========\n",
      "Index: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8732394366197183 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.7916666666666666 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.7910447761194029 1\n",
      "LLM 0.9558823529411765 1\n",
      "==========\n",
      "Index: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.86 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8115942028985508 1\n",
      "LLM 0.9855072463768116 1\n",
      "==========\n",
      "Index: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8470588235294118 1\n",
      "LLM 0.9659090909090909 3\n",
      "==========\n",
      "Index: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8604651162790697 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8048780487804879 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8103448275862069 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8571428571428571 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8382352941176471 1\n",
      "LLM 0.9701492537313433 1\n",
      "==========\n",
      "Index: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.85 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8705882352941177 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8269230769230769 1\n",
      "LLM 0.9514563106796117 1\n",
      "==========\n",
      "Index: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8507462686567164 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8115942028985508 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8817204301075269 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8536585365853658 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8852459016393442 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8589743589743589 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8723404255319149 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.855072463768116 1\n",
      "LLM 0.9928057553956835 1\n",
      "==========\n",
      "Index: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8809523809523809 1\n",
      "LLM 0.9822485207100592 1\n",
      "==========\n",
      "Index: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8152173913043478 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8571428571428571 1\n",
      "LLM 0.9940828402366864 1\n",
      "==========\n",
      "Index: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8805970149253731 1\n",
      "LLM 0.9925925925925926 1\n",
      "==========\n",
      "Index: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8723404255319149 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.9066666666666666 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8387096774193549 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.875 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.847457627118644 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8888888888888888 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8783783783783784 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8936170212765957 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8571428571428571 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8941176470588236 1\n",
      "LLM 0.9941520467836257 1\n",
      "==========\n",
      "Index: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8875 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.859375 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.7796610169491526 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8586956521739131 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.875 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8076923076923077 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.85 1\n",
      "LLM 0.8717948717948718 1\n",
      "==========\n",
      "Index: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8245614035087719 1\n",
      "LLM 0.9482758620689655 1\n",
      "==========\n",
      "Index: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8333333333333334 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8513513513513513 1\n",
      "LLM 0.9932885906040269 1\n",
      "==========\n",
      "Index: 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8695652173913043 1\n",
      "LLM 0.9891304347826086 1\n",
      "==========\n",
      "Index: 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8679245283018868 1\n",
      "LLM 0.9504950495049505 1\n",
      "==========\n",
      "Index: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8222222222222222 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.9318181818181818 1\n",
      "LLM 0.9772727272727273 1\n",
      "==========\n",
      "Index: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8125 1\n",
      "LLM 0.953125 2\n",
      "==========\n",
      "Index: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8870967741935484 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8571428571428571 1\n",
      "LLM 0.994535519125683 1\n",
      "==========\n",
      "Index: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8181818181818182 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.875 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8536585365853658 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8108108108108109 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.9016393442622951 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8695652173913043 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8404255319148937 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8431372549019608 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8589743589743589 1\n",
      "LLM 0.9685534591194969 1\n",
      "==========\n",
      "Index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8734177215189873 1\n",
      "LLM 0.9873417721518988 1\n",
      "==========\n",
      "Index: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8 1\n",
      "LLM 0.9541284403669725 1\n",
      "==========\n",
      "Index: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.875 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8350515463917526 1\n",
      "LLM 0.9948186528497409 1\n",
      "==========\n",
      "Index: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet 0.8425925925925926 1\n",
      "LLM 1.0 0\n",
      "==========\n",
      "Index: 99\n",
      "CoAtNet 0.8333333333333334 1\n",
      "LLM 1.0 0\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "llm_accs = []\n",
    "llm_ws = []\n",
    "llm_sen = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Index: {index}\")\n",
    "    predicted_sentence = row['Predicted Sentence']\n",
    "    true_sentence = row['True Sentence']\n",
    "    llm_sentence = get_llm_sentence(predicted_sentence)\n",
    "    llm_sentence = llm_postprocess(llm_sentence)\n",
    "    \n",
    "    accuracy, wrong_syllables = compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence)\n",
    "    print(\"CoAtNet\", accuracy, wrong_syllables)\n",
    "    \n",
    "    accuracy, wrong_syllables = compute_accuracy_and_wrong_syllables(true_sentence, llm_sentence)\n",
    "    print(\"LLM\", accuracy, wrong_syllables)\n",
    "    llm_sen.append(llm_sentence)\n",
    "    llm_accs.append(accuracy)\n",
    "    llm_ws.append(wrong_syllables)\n",
    "    print(\"==========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b6a6e1c-d8dc-4797-ae42-18032792a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LLM Sentence'] = llm_sen\n",
    "df['LLM Accuracy'] = llm_accs\n",
    "df['LLM Wrong syllables'] = llm_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fc5120e-f6ca-4da5-9799-bf5909a665f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Sentence</th>\n",
       "      <th>Predicted Sentence</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Wrong syllables</th>\n",
       "      <th>LLM Sentence</th>\n",
       "      <th>LLM Accuracy</th>\n",
       "      <th>LLM Wrong syllables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the government will be investing in infrastruc...</td>\n",
       "      <td>the?government?will?be?investing?in?infrastruc...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>the government will be investing in infrastruc...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cosmologists will be studying the evolution of...</td>\n",
       "      <td>xosmologists?will?be?studying?the?evolution?of...</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>1</td>\n",
       "      <td>xosmologists will be studying the evolution of...</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>predictive analytics will drive the developmen...</td>\n",
       "      <td>predictive?amalytics?will?drive?the?denelopmen...</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>2</td>\n",
       "      <td>predictive analytics will drive the developmen...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fashion houses have embraced the use of sustai...</td>\n",
       "      <td>fashionwhouses?have?embraced?the?use?of?sustai...</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>1</td>\n",
       "      <td>fashion houses have embraced the use of sustai...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they were rearended by a distracted driver</td>\n",
       "      <td>they?were?rearended?by?a?distracted?driver</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>they were rearended by a distracted driver</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tomorrow i will be teaching a new lesson on ma...</td>\n",
       "      <td>tomorrow?i?will?ne?geaching?a?new?lesson?on?ma...</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>2</td>\n",
       "      <td>tomorrow i will negeaching a new lesson on mat...</td>\n",
       "      <td>0.954128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>bangladeshi culture will be celebrated worldwide</td>\n",
       "      <td>bamgladeshi?culture?will?be?celebrated?worldwide</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1</td>\n",
       "      <td>bangladeshi culture will be celebrated worldwide</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>the achievements of women in stem have fostere...</td>\n",
       "      <td>thelachievements?of?women?in?stemfhave?fostere...</td>\n",
       "      <td>0.958763</td>\n",
       "      <td>4</td>\n",
       "      <td>theachievements of women in stem have fostered...</td>\n",
       "      <td>0.994819</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>over the past decade women have contributed to...</td>\n",
       "      <td>over?the?past?decade?women?have?contrinuted?to...</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>2</td>\n",
       "      <td>over the past decade women have contributed to...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>she traveled to japan and immersed herself in ...</td>\n",
       "      <td>she?traveled?to?japan?and?immersed?herself?in?...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>she traveled to japan and immersed herself in ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        True Sentence  \\\n",
       "0   the government will be investing in infrastruc...   \n",
       "1   cosmologists will be studying the evolution of...   \n",
       "2   predictive analytics will drive the developmen...   \n",
       "3   fashion houses have embraced the use of sustai...   \n",
       "4          they were rearended by a distracted driver   \n",
       "..                                                ...   \n",
       "95  tomorrow i will be teaching a new lesson on ma...   \n",
       "96   bangladeshi culture will be celebrated worldwide   \n",
       "97  the achievements of women in stem have fostere...   \n",
       "98  over the past decade women have contributed to...   \n",
       "99  she traveled to japan and immersed herself in ...   \n",
       "\n",
       "                                   Predicted Sentence  Accuracy  \\\n",
       "0   the?government?will?be?investing?in?infrastruc...  1.000000   \n",
       "1   xosmologists?will?be?studying?the?evolution?of...  0.987179   \n",
       "2   predictive?amalytics?will?drive?the?denelopmen...  0.974359   \n",
       "3   fashionwhouses?have?embraced?the?use?of?sustai...  0.987952   \n",
       "4          they?were?rearended?by?a?distracted?driver  1.000000   \n",
       "..                                                ...       ...   \n",
       "95  tomorrow?i?will?ne?geaching?a?new?lesson?on?ma...  0.963636   \n",
       "96   bamgladeshi?culture?will?be?celebrated?worldwide  0.979167   \n",
       "97  thelachievements?of?women?in?stemfhave?fostere...  0.958763   \n",
       "98  over?the?past?decade?women?have?contrinuted?to...  0.981481   \n",
       "99  she?traveled?to?japan?and?immersed?herself?in?...  1.000000   \n",
       "\n",
       "    Wrong syllables                                       LLM Sentence  \\\n",
       "0                 0  the government will be investing in infrastruc...   \n",
       "1                 1  xosmologists will be studying the evolution of...   \n",
       "2                 2  predictive analytics will drive the developmen...   \n",
       "3                 1  fashion houses have embraced the use of sustai...   \n",
       "4                 0         they were rearended by a distracted driver   \n",
       "..              ...                                                ...   \n",
       "95                2  tomorrow i will negeaching a new lesson on mat...   \n",
       "96                1   bangladeshi culture will be celebrated worldwide   \n",
       "97                4  theachievements of women in stem have fostered...   \n",
       "98                2  over the past decade women have contributed to...   \n",
       "99                0  she traveled to japan and immersed herself in ...   \n",
       "\n",
       "    LLM Accuracy  LLM Wrong syllables  \n",
       "0       1.000000                    0  \n",
       "1       0.987179                    1  \n",
       "2       1.000000                    0  \n",
       "3       1.000000                    0  \n",
       "4       1.000000                    0  \n",
       "..           ...                  ...  \n",
       "95      0.954128                    1  \n",
       "96      1.000000                    0  \n",
       "97      0.994819                    1  \n",
       "98      1.000000                    0  \n",
       "99      1.000000                    0  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "528d792f-cd62-4cdc-964b-72b67f8b0bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tresults_1_llm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15db175b-4e27-446c-bd0a-7617c2fc589b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709f8605-e182-4715-8b85-45c361326b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rosa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
