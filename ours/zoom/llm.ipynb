{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf1037b-b3f1-476d-9b25-435f99d4250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b39ba4-2671-47ba-aec8-4f96bc9a5091",
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli whoami              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b9bbb5-f5e0-4c33-8ed1-21b99bf247a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4511ae51-a286-4be8-8f78-fa01c31eee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"results/1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42636cd0-35aa-48ba-a401-539cf39edbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    print(f\"sentence: {df['Predicted Sentence'][i]}\")\n",
    "    print(f\"corrected: {df['True Sentence'][i]}\")\n",
    "    print()  # Empty line for spacing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618dc25e-4062-48a9-8856-dcce44e19d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b2d7e0-8c31-45c5-82ef-47a60fb57704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messages(sentence):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in correcting typos in sentences.\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "Here are examples of sentences with typos; learn from them:\n",
    "\n",
    "    sentence: by 2480 genetic engineers will havegcreated organisgs capable of surviving in space without life support\n",
    "    corrected: by 2480 genetic engineers will have created organisms capable of surviving in space without life support\n",
    "\n",
    "    sentence: by 2510 the local government will have been investing in green infrastructure for generations\n",
    "    corrected: by 2510 the local government will have been investing in green infrastructure for generations\n",
    "\n",
    "Now, please correct this sentence and output only the corrected version with no additional text:\n",
    "    \n",
    "{target_sentence}\n",
    "        \"\"\".format(target_sentence=sentence)},\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8d70dc-67c6-48dd-937b-210ee2a4cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_sentence(sentence):\n",
    "    messages = get_messages(sentence)\n",
    "    outputs = pipe(\n",
    "        messages,\n",
    "        max_new_tokens=256,\n",
    "        # pad_token_id=pipe.tokenizer.eos_token_id\n",
    "    )\n",
    "    llm_sentence = outputs[0][\"generated_text\"][-1][\"content\"]\n",
    "    return llm_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7377f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_llm_sentence(\"My name it John.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4a1fb0-2b1f-4b8a-918b-0c977d26b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_postprocess(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    # remove all non a-z0-9 \n",
    "    sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98936f58-17fa-424b-839c-9d421a3253f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence):\n",
    "    # Character-level accuracy using SequenceMatcher\n",
    "    char_matcher = difflib.SequenceMatcher(None, true_sentence, predicted_sentence)\n",
    "    accuracy = char_matcher.ratio()\n",
    "    \n",
    "    # Word-level wrong syllable count using SequenceMatcher on word lists\n",
    "    true_words = true_sentence.split()\n",
    "    predicted_words = predicted_sentence.split()\n",
    "    word_matcher = difflib.SequenceMatcher(None, true_words, predicted_words)\n",
    "    \n",
    "    # Calculate wrong syllables based on insert, delete, and replace operations\n",
    "    wrong_syllables = sum(1 for tag, _, _, _, _ in word_matcher.get_opcodes() if tag in ('insert', 'delete', 'replace'))\n",
    "    \n",
    "    return accuracy, wrong_syllables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755ca78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ca5a8-497e-4c9a-b77f-29350c26de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_accs = []\n",
    "llm_ws = []\n",
    "llm_sen = []\n",
    "total=len(df)\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=total):\n",
    "    should_print = index % 100 == 0\n",
    "    predicted_sentence = row['Predicted Sentence']\n",
    "    true_sentence = row['True Sentence']\n",
    "    accuracy, wrong_syllables = compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence)\n",
    "    if should_print:\n",
    "        print(f\"Index: {index} of {total}\")\n",
    "        print(\"CoAtNet\", accuracy, wrong_syllables)\n",
    "    \n",
    "    llm_sentence = get_llm_sentence(predicted_sentence)\n",
    "    llm_sentence = llm_postprocess(llm_sentence)\n",
    "    accuracy, wrong_syllables = compute_accuracy_and_wrong_syllables(true_sentence, llm_sentence)\n",
    "    if should_print:\n",
    "        print(\"LLM\", accuracy, wrong_syllables)\n",
    "        print(\"==========\")\n",
    "    \n",
    "    llm_sen.append(llm_sentence)\n",
    "    llm_accs.append(accuracy)\n",
    "    llm_ws.append(wrong_syllables)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6a6e1c-d8dc-4797-ae42-18032792a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LLM Sentence'] = llm_sen\n",
    "df['LLM Accuracy'] = llm_accs\n",
    "df['LLM Wrong syllables'] = llm_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf8af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average accuracy\n",
    "llm_avg_accuracy = sum(llm_accs) / len(llm_accs)\n",
    "# sum of wrong syllables\n",
    "llm_sum_wrong_syllables = sum(llm_ws)\n",
    "\n",
    "print(f\"LLM Average Accuracy: {llm_avg_accuracy}\")\n",
    "print(f\"LLM Sum of Wrong Syllables: {llm_sum_wrong_syllables}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5e38a6",
   "metadata": {},
   "source": [
    "- 1B\n",
    "- NF 1\n",
    "- LLM Average Accuracy: 0.9564564414385444\n",
    "- LLM Sum of Wrong Syllables: 525\n",
    "---\n",
    "- 1B\n",
    "- NF 5\n",
    "- LLM Average Accuracy: 0.7679998762433198\n",
    "- LLM Sum of Wrong Syllables: 2239\n",
    "---\n",
    "- 1B\n",
    "- NF 6\n",
    "- LLM Average Accuracy: 0.6005106454866648\n",
    "- LLM Sum of Wrong Syllables: 2343\n",
    "\n",
    "---\n",
    "- 3B\n",
    "- NF 1\n",
    "- LLM Average Accuracy: 0.9935726024752972\n",
    "- LLM Sum of Wrong Syllables: 220\n",
    "---\n",
    "- 3B\n",
    "- NF 5\n",
    "- LLM Average Accuracy: 0.8926553222468829\n",
    "- LLM Sum of Wrong Syllables: 1701\n",
    "---\n",
    "- 3B\n",
    "- NF 6\n",
    "- LLM Average Accuracy: 0.6951608020737897\n",
    "- LLM Sum of Wrong Syllables: 2622\n",
    "\n",
    "---\n",
    "\n",
    "- 8B\n",
    "- NF 1\n",
    "- LLM Average Accuracy: 0.9964405469123979\n",
    "- LLM Sum of Wrong Syllables: 118\n",
    "---\n",
    "- 8B\n",
    "- NF 5\n",
    "- LLM Average Accuracy: 0.9221289253837536\n",
    "- LLM Sum of Wrong Syllables: 1248\n",
    "---\n",
    "- 8B\n",
    "- NF 6\n",
    "- LLM Average Accuracy: 0.7523719200663457\n",
    "- LLM Sum of Wrong Syllables: 2413\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d792f-cd62-4cdc-964b-72b67f8b0bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results/llama3_1_8b/1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15db175b-4e27-446c-bd0a-7617c2fc589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709f8605-e182-4715-8b85-45c361326b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rosa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
