{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import torchaudio\n",
    "import csv\n",
    "import string\n",
    "\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torchaudio.transforms import TimeMasking, FrequencyMasking\n",
    "from torchvision.ops import SqueezeExcitation\n",
    "from torchinfo import summary\n",
    "from torchsummary import summary\n",
    "from torchvision.ops import SqueezeExcitation\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from scipy.io import wavfile\n",
    "from functools import reduce\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_s = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "labels = list(keys_s)\n",
    "keys = [k + '.wav' for k in labels]\n",
    "data_dict = {'Key':[], 'File':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolator(signal, sample_rate, size, scan, before, after, threshold, show=False):\n",
    "    strokes = []\n",
    "    # -- signal'\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(signal, sr=sample_rate)\n",
    "    fft = librosa.stft(signal, n_fft=size, hop_length=scan)\n",
    "    energy = np.abs(np.sum(fft, axis=0)).astype(float)\n",
    "    # norm = np.linalg.norm(energy)\n",
    "    # energy = energy/norm\n",
    "    # -- energy'\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(energy)\n",
    "    threshed = energy > threshold\n",
    "    # -- peaks'\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(threshed.astype(float))\n",
    "    peaks = np.where(threshed == True)[0]\n",
    "    peak_count = len(peaks)\n",
    "    prev_end = sample_rate*0.1*(-1)\n",
    "    # '-- isolating keystrokes'\n",
    "    for i in range(peak_count):\n",
    "        this_peak = peaks[i]\n",
    "        timestamp = (this_peak*scan) + size//2\n",
    "        if timestamp > prev_end + (0.1*sample_rate):\n",
    "            keystroke = signal[timestamp-before:timestamp+after]\n",
    "            strokes.append(torch.tensor(keystroke)[None, :])\n",
    "            if show:\n",
    "                plt.figure(figsize=(7, 2))\n",
    "                librosa.display.waveshow(keystroke, sr=sample_rate)\n",
    "            prev_end = timestamp+after\n",
    "    return strokes\n",
    "\n",
    "def convert_to_df(AUDIO_FILE):\n",
    "    for i, File in enumerate(keys):\n",
    "        loc = AUDIO_FILE + File\n",
    "        samples, sample_rate = librosa.load(loc, sr=None)\n",
    "        #samples = samples[round(1*sample_rate):]\n",
    "        strokes = []\n",
    "        prom = 0.06\n",
    "        step = 0.005\n",
    "        while not len(strokes) == 25:\n",
    "            strokes = isolator(samples[1*sample_rate:], sample_rate, 48, 24, 2400, 12000, prom, False)\n",
    "            if len(strokes) < 25:\n",
    "                prom -= step\n",
    "            if len(strokes) > 25:\n",
    "                prom += step\n",
    "            if prom <= 0:\n",
    "                print('-- not possible for: ',File)\n",
    "                break\n",
    "            step = step*0.99\n",
    "        label = [labels[i]]*len(strokes)\n",
    "        data_dict['Key'] += label\n",
    "        data_dict['File'] += strokes\n",
    "\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    mapper = {}\n",
    "    counter = 0\n",
    "    for l in df['Key']:\n",
    "        if not l in mapper:\n",
    "            mapper[l] = counter\n",
    "            counter += 1\n",
    "    df.replace({'Key': mapper}, inplace=True)\n",
    "    return df, sample_rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Key                                               File\n",
      "0   0  [[tensor(-6.1035e-05), tensor(-6.1035e-05), te...\n",
      "1   0  [[tensor(0.), tensor(-3.0518e-05), tensor(-3.0...\n",
      "2   0  [[tensor(3.0518e-05), tensor(3.0518e-05), tens...\n",
      "3   0  [[tensor(-0.0002), tensor(-0.0002), tensor(-0....\n",
      "4   0  [[tensor(6.1035e-05), tensor(6.1035e-05), tens...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Key     900 non-null    object\n",
      " 1   File    900 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 14.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_frame, sr = convert_to_df(\"../../dataset/Zoom/\")\n",
    "\n",
    "print(data_frame.head())\n",
    "print(data_frame.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 32000\n",
      "630 180 90\n"
     ]
    }
   ],
   "source": [
    "train_set, tmp_set = train_test_split(data_frame, test_size=0.3, stratify=data_frame['Key'])\n",
    "val_set, test_set = train_test_split(tmp_set, test_size=0.33, stratify=tmp_set['Key'])\n",
    "\n",
    "print(\"Sample rate:\", sr)\n",
    "print(len(train_set), len(val_set), len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_name, transform = None, aug = None):\n",
    "        df = file_name\n",
    "        self.transform = transform\n",
    "        self.aug = aug\n",
    "        self.labels = df['Key']\n",
    "        self.values = df['File']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels.iloc[index]\n",
    "        value = self.values.iloc[index]\n",
    "        waveform = self.values.iloc[index]\n",
    "        label = self.labels.iloc[index]\n",
    "        if self.transform:\n",
    "            waveform = waveform.numpy()\n",
    "            waveform = waveform.flatten()\n",
    "            waveform = self.transform(waveform)\n",
    "        if self.aug:\n",
    "            waveform = self.aug(waveform)\n",
    "        return waveform, label\n",
    "\n",
    "class ToMelSpectrogram:\n",
    "    def __call__(self, samples):\n",
    "#         samples = np.array(samples)\n",
    "        spec = librosa.feature.melspectrogram(y = samples, sr = sr, n_mels=64, n_fft=2048, win_length=1024, hop_length=226)\n",
    "        return librosa.power_to_db(spec)\n",
    "\n",
    "class TimeShifting():\n",
    "    def __call__(self, samples):\n",
    "        samples = samples.numpy()\n",
    "        samples = samples.flatten()\n",
    "        \n",
    "        shift = int(len(samples) * 0.4)\n",
    "        random_shift =random.randint(0, shift)\n",
    "        data_roll = np.roll(samples, random_shift)\n",
    "        return data_roll\n",
    "    \n",
    "class SpecAugment():\n",
    "    def __call__(self, samples):\n",
    "        num_mask = 2\n",
    "        freq_masking_max_percentage=0.10\n",
    "        time_masking_max_percentage=0.10\n",
    "        spec = samples.copy()\n",
    "        mean_value = spec.mean()\n",
    "        for i in range(num_mask):\n",
    "            all_frames_num, all_freqs_num = spec.shape[1], spec.shape[1] \n",
    "            freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n",
    "\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            spec[:, f0:f0 + num_freqs_to_mask] = mean_value\n",
    "\n",
    "            time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            spec[t0:t0 + num_frames_to_mask, :] = mean_value\n",
    "        return spec\n",
    "\n",
    "aug = Compose([\n",
    "    TimeShifting(),\n",
    "    ToMelSpectrogram(),\n",
    "    SpecAugment(),\n",
    "    ToTensor()\n",
    "    ])\n",
    "\n",
    "transform = Compose([\n",
    "    ToMelSpectrogram(),\n",
    "    ToTensor()])\n",
    "        \n",
    "train_set = MyDataset(train_set, aug = aug)\n",
    "val_set = MyDataset(val_set, transform = transform)\n",
    "test_set = MyDataset(test_set, transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set image (augmented vs non-augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1.imshow(train_set[0][0][0], cmap='viridis')\n",
    "ax2.imshow(val_set[0][0][0], cmap='viridis')\n",
    "print(train_set[0][0][0].shape)\n",
    "ax1.grid(False)\n",
    "ax2.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 36\n"
     ]
    }
   ],
   "source": [
    "print(\"number of classes:\", len(np.unique(data_frame['Key'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoAtNet (Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stem(nn.Sequential):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__(\n",
    "            nn.Conv2d(1, out_channels, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor=4):\n",
    "        super().__init__()\n",
    "        self.mb_conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.Conv2d(in_channels, in_channels * expansion_factor, kernel_size=1),\n",
    "            nn.BatchNorm2d(in_channels * expansion_factor),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(in_channels * expansion_factor, in_channels * expansion_factor, kernel_size=3, padding=1, groups=in_channels * expansion_factor),\n",
    "            nn.BatchNorm2d(in_channels * expansion_factor),\n",
    "            nn.GELU(),\n",
    "            SqueezeExcitation(in_channels * expansion_factor, in_channels, activation=nn.GELU),\n",
    "            nn.Conv2d(in_channels * expansion_factor, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.mb_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsamplingMBConv(MBConv):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor=4):\n",
    "        super().__init__(in_channels, out_channels, expansion_factor=4)\n",
    "        self.mb_conv[1] = nn.Conv2d(in_channels, in_channels * expansion_factor, kernel_size=1, stride = 2)\n",
    "        self.channel_projection = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.channel_projection(self.pool(x)) + self.mb_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativeAttention2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, image_size, heads=8, head_size=32):\n",
    "        super().__init__()\n",
    "        heads = out_channels // head_size\n",
    "        self.heads = heads\n",
    "        self.head_size = head_size\n",
    "        self.image_size = image_size\n",
    "        self.head_dim = heads * head_size\n",
    "        self.attend = nn.Softmax(dim=-2) # Taken from My_CoAtNet\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.to_q = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_k = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_v = nn.Linear(in_channels, self.head_dim)\n",
    "        self.to_output = nn.Sequential(\n",
    "            nn.Linear(self.head_dim, out_channels),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.normalization = nn.LayerNorm(in_channels)\n",
    "        \n",
    "        self.relative_bias = nn.Parameter(torch.randn(heads, (2 * image_size - 1) * (2 * image_size - 1)))\n",
    "        self.register_buffer(\"relative_indices\", self.get_indices(image_size, image_size)) # Taken from My_CoAtNet\n",
    "        self.precomputed_relative_bias = None\n",
    "    \n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "    \n",
    "    def get_relative_biases(self):\n",
    "        # Relative bias caching mentioned in CoAtNet: Marrying Convolution and Attention for All Data Sizes\n",
    "        if not self.training:\n",
    "            return self.precomputed_relative_bias\n",
    "        # Taken from od My_CoAtNet\n",
    "        indices = self.relative_indices.expand(self.heads, -1)\n",
    "        rel_pos_enc = self.relative_bias.gather(-1, indices)\n",
    "        rel_pos_enc = rel_pos_enc.unflatten(-1, (self.image_size * self.image_size, self.image_size * self.image_size))\n",
    "        return rel_pos_enc\n",
    "    \n",
    "    def reshape_for_linear(self, x):\n",
    "        b, _, _, _ = x.shape\n",
    "        return x.reshape(b, self.image_size * self.image_size, self.in_channels)\n",
    "    \n",
    "    def attention_score(self, x):\n",
    "        b, _, h, _ = x.shape\n",
    "        q = self.to_q(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        k = self.to_k(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        dots = torch.matmul(k.transpose(-1, -2), q) / math.sqrt(self.head_dim)\n",
    "        relative_biases_indexed = self.get_relative_biases()\n",
    "        return self.attend(dots + relative_biases_indexed)\n",
    "    \n",
    "    def relative_attention(self, x):\n",
    "        b, _, _, _ = x.shape\n",
    "        v = self.to_v(self.reshape_for_linear(x)).view(b, self.heads, self.head_size, -1) # Taken from My_CoAtNet\n",
    "        out = torch.matmul(v, self.attention_score(x)) # I figured this out after debugging (Still the same as My_CoAtNet)\n",
    "        out = out.view(b, self.image_size, self.image_size, -1)\n",
    "        return self.to_output(out).view(b, self.out_channels, self.image_size, self.image_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.relative_attention(self.norm(x))\n",
    "    \n",
    "    def train(self, training):\n",
    "        if not training:\n",
    "            self.precomputed_relative_bias = self.get_relative_biases()\n",
    "        super().train(training)\n",
    "        \n",
    "    # Taken from My_CoAtNet\n",
    "    @staticmethod\n",
    "    def get_indices(h, w):\n",
    "        y = torch.arange(h, dtype=torch.long)\n",
    "        x = torch.arange(w, dtype=torch.long)\n",
    "        \n",
    "        y1, x1, y2, x2 = torch.meshgrid(y, x, y, x)\n",
    "        indices = (y1 - y2 + h - 1) * (2 * w - 1) + x1 - x2 + w - 1\n",
    "        indices = indices.flatten()\n",
    "        \n",
    "        return indices\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsamplingRelativeAttention2d(RelativeAttention2d):\n",
    "    def __init__(self, in_channels, out_channels, image_size, heads=8, head_size=32):\n",
    "        super().__init__(in_channels, out_channels, image_size, heads=8, head_size=32)\n",
    "        self.channel_projection = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.normalization = nn.LayerNorm(in_channels)\n",
    "\n",
    "\n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.channel_projection(self.pool(x)) + self.relative_attention(self.pool(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, out_channels, expansion_factor=4):\n",
    "        super().__init__()\n",
    "        hidden_dim = out_channels * expansion_factor\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(out_channels, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, out_channels),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.normalization = nn.LayerNorm(out_channels)\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    \n",
    "    def norm(self, x):\n",
    "        x = x.transpose(1, -1) # Taken from My_CoAtNet\n",
    "        x = self.normalization(x)\n",
    "        x = x.transpose(-1, 1) # Taken from My_CoAtNet\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        old_shape = x.shape\n",
    "        batch_size = old_shape[0]\n",
    "        return x + torch.reshape(self.ffn(torch.reshape(self.norm(x), (batch_size, -1, self.out_channels))), old_shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleTransformerBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, image_size):\n",
    "        attention = DownsamplingRelativeAttention2d(in_channels, out_channels, image_size)\n",
    "        ffn = FeedForwardNetwork(out_channels)\n",
    "        super().__init__(\n",
    "            attention,\n",
    "            ffn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, image_size):\n",
    "        attention = RelativeAttention2d(in_channels, out_channels, image_size)\n",
    "        ffn = FeedForwardNetwork(out_channels)\n",
    "        super().__init__(\n",
    "            attention,\n",
    "            ffn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(in_channels, num_classes)\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.pool(x)\n",
    "        x = torch.reshape(x, (batch_size, -1, self.in_channels))\n",
    "        return torch.squeeze(self.fc(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCoAtNet(nn.Sequential):\n",
    "    def __init__(self, nums_blocks, layer_out_channels, num_classes=36):\n",
    "        s0 = nn.Sequential(Stem(layer_out_channels[0]))\n",
    "        \n",
    "        s1 = [DownsamplingMBConv(layer_out_channels[0], layer_out_channels[1])]\n",
    "        for i in range(nums_blocks[1] - 1):\n",
    "            s1.append(MBConv(layer_out_channels[1], layer_out_channels[1]))\n",
    "        s1 = nn.Sequential(*s1)\n",
    "        \n",
    "        s2 = [DownsamplingMBConv(layer_out_channels[1], layer_out_channels[2])]\n",
    "        for i in range(nums_blocks[2] - 1):\n",
    "            s2.append(MBConv(layer_out_channels[2], layer_out_channels[2]))\n",
    "        s2 = nn.Sequential(*s2)\n",
    "        \n",
    "        s3 = [DownsampleTransformerBlock(layer_out_channels[2], layer_out_channels[3], 64 // 16)]\n",
    "        for i in range(nums_blocks[3] - 1):\n",
    "            s3.append(TransformerBlock(layer_out_channels[3], layer_out_channels[3], 64 // 16))\n",
    "        s3 = nn.Sequential(*s3)\n",
    "        \n",
    "        s4 = [DownsampleTransformerBlock(layer_out_channels[3], layer_out_channels[4], 64 // 32)]\n",
    "        for i in range(nums_blocks[4] - 1):\n",
    "            s4.append(TransformerBlock(layer_out_channels[4], layer_out_channels[4], 64 // 32))\n",
    "        s4 = nn.Sequential(*s4)\n",
    "        \n",
    "        head = Head(layer_out_channels[4], num_classes)\n",
    "        \n",
    "        super().__init__(\n",
    "            s0,\n",
    "            s1,\n",
    "            s2,\n",
    "            s3,\n",
    "            s4,\n",
    "            head\n",
    "        )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seyyedaliayati\\AppData\\Local\\anaconda3\\envs\\rosa\\Lib\\site-packages\\torch\\functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3610.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# CoAtNet-1\n",
    "nums_blocks = [2, 2, 3, 5, 2]           # L\n",
    "channels = [64, 96, 192, 384, 768]      # D\n",
    "\n",
    "model = MyCoAtNet(nums_blocks, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_linear(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None: nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.apply(init_linear)\n",
    "model.to(device)\n",
    "\n",
    "print(\"Number of parameters: {:,}\".format(sum(p.numel() for p in model.parameters())))\n",
    "\n",
    "summary(model, input_size=(1, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seyyedaliayati\\AppData\\Local\\Temp\\ipykernel_27488\\2176242892.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"CoAtNet-1-Best-Zoom.pkl\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyCoAtNet(\n",
       "  (0): Sequential(\n",
       "    (0): Stem(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): DownsamplingMBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(96, 384, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "        (5): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (channel_projection): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (mb_conv): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        (5): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): GELU(approximate='none')\n",
       "        (7): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): GELU(approximate='none')\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=192, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): DownsampleTransformerBlock(\n",
       "      (0): DownsamplingRelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=384, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (channel_projection): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): RelativeAttention2d(\n",
       "        (attend): Softmax(dim=-2)\n",
       "        (to_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_output): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): FeedForwardNetwork(\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.3, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "        (normalization): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Head(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=768, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.load_state_dict(torch.load(\"CoAtNet-1-Best-Zoom.pkl\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from My_CoAtNet\n",
    "def separate_parameters(model):\n",
    "    parameters_decay = set()\n",
    "    parameters_no_decay = set()\n",
    "    modules_weight_decay = (nn.Linear, nn.Conv2d)\n",
    "    modules_no_weight_decay = (nn.LayerNorm, nn.BatchNorm2d)\n",
    "    \n",
    "    for m_name, m in model.named_modules():\n",
    "        for param_name, param in m.named_parameters():\n",
    "            full_param_name = f\"{m_name}.{param_name}\" if m_name else param_name\n",
    "\n",
    "            if isinstance(m, modules_no_weight_decay):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif param_name.endswith(\"bias\"):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif isinstance(m, modules_weight_decay):\n",
    "                parameters_decay.add(full_param_name)\n",
    "    \n",
    "    # sanity check\n",
    "    assert len(parameters_decay & parameters_no_decay) == 0\n",
    "    assert len(parameters_decay) + len(parameters_no_decay) == len(list(model.parameters()))\n",
    "\n",
    "    return parameters_decay, parameters_no_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 5e-4\n",
    "weight_decay = 0.1\n",
    "num_epochs = 1100\n",
    "min_learning_rate = 1e-6\n",
    "\n",
    "param_dict = {pn: p for pn, p in model.named_parameters()}\n",
    "parameters_decay, parameters_no_decay = separate_parameters(model)\n",
    "parameter_groups = [\n",
    "    {\"params\": [param_dict[pn] for pn in parameters_decay], \"weight_decay\": weight_decay},\n",
    "    {\"params\": [param_dict[pn] for pn in parameters_no_decay], \"weight_decay\": 0.0},\n",
    "]\n",
    "optimizer = torch.optim.Adam(parameter_groups, lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=min_learning_rate / learning_rate, total_iters=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from My_CoAtNet\n",
    "def plot_results(train_losses, train_accuracies, val_losses, val_accuracies):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.legend([\"Training loss\", \"Validation loss\"], loc =  \"best\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(train_accuracies)\n",
    "    plt.plot(val_accuracies)\n",
    "    plt.legend([\"Training accuracy\", \"Validation accuracy\"], loc =  \"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"CoAtNet-1-Best-Zoom.pkl\"\n",
    "model_path = \"CoAtNet-1-Zoom.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings from indices to syllables and vice versa\n",
    "digits_and_syllables = list('0123456789abcdefghijklmnopqrstuvwxyz')\n",
    "idx_to_syllable = {idx: syllable for idx, syllable in enumerate(digits_and_syllables)}\n",
    "syllable_to_idx = {syllable: idx for idx, syllable in idx_to_syllable.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine test and validation datasets\n",
    "combined_dataset = ConcatDataset([val_set, test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from syllables to dataset indices\n",
    "syllable_to_indices = {}\n",
    "for idx in range(len(combined_dataset)):\n",
    "    _, label = combined_dataset[idx]\n",
    "    # label = label.item() \n",
    "    syllable = idx_to_syllable[label]\n",
    "    if syllable not in syllable_to_indices:\n",
    "        syllable_to_indices[syllable] = []\n",
    "    syllable_to_indices[syllable].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process sentences into syllables\n",
    "def get_syllables(sentence):\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    # sentence = sentence.replace(' ',  '').lower()\n",
    "    syllables = list(sentence)\n",
    "    return syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 1000\n"
     ]
    }
   ],
   "source": [
    "# Read sentences from the text file\n",
    "with open('../sentences/sentences.txt', 'r') as f:\n",
    "    sentences = f.readlines()\n",
    "\n",
    "print(\"Number of sentences:\", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence):\n",
    "    # Character-level accuracy using SequenceMatcher\n",
    "    char_matcher = difflib.SequenceMatcher(None, true_sentence, predicted_sentence)\n",
    "    accuracy = char_matcher.ratio()\n",
    "    \n",
    "    # Word-level wrong syllable count using SequenceMatcher on word lists\n",
    "    true_words = true_sentence.split()\n",
    "    predicted_words = predicted_sentence.split()\n",
    "    word_matcher = difflib.SequenceMatcher(None, true_words, predicted_words)\n",
    "    \n",
    "    # Calculate wrong syllables based on insert, delete, and replace operations\n",
    "    wrong_syllables = sum(1 for tag, _, _, _, _ in word_matcher.get_opcodes() if tag in ('insert', 'delete', 'replace'))\n",
    "    \n",
    "    return accuracy, wrong_syllables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f295dae4dcec49b9aa25723b841ef9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process each sentence\n",
    "noise_factor = 6\n",
    "results = []\n",
    "\n",
    "for sentence in tqdm(sentences):\n",
    "    sentence = sentence.strip()\n",
    "    syllables = get_syllables(sentence)\n",
    "    true_sentence = ''.join(syllables)\n",
    "    predicted_syllables = []\n",
    "\n",
    "    for syllable in syllables:\n",
    "        if syllable in syllable_to_indices:\n",
    "            # Randomly select an index for the syllable\n",
    "            idx = random.choice(syllable_to_indices[syllable])\n",
    "            # Retrieve the image and label from the dataset\n",
    "            image, _ = combined_dataset[idx]\n",
    "\n",
    "            noise = torch.randn_like(image) * noise_factor\n",
    "            image = image + noise\n",
    "            image = image.unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "                output = output.reshape(1, -1)\n",
    "                _, predicted_idx = torch.max(output.data, 1)\n",
    "                predicted_syllable = idx_to_syllable[predicted_idx.item()]\n",
    "        else:\n",
    "            if random.random() < 0.90:\n",
    "                predicted_syllable = ' '\n",
    "            else:\n",
    "                predicted_syllable = random.choice(digits_and_syllables)\n",
    "        predicted_syllables.append(predicted_syllable)\n",
    "    \n",
    "    predicted_sentence = ''.join(predicted_syllables)\n",
    "    accuracy, wrong_syllables = compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence)\n",
    "    results.append([true_sentence, predicted_sentence, accuracy, wrong_syllables])\n",
    "    # print(f\"accuracy: {accuracy}, wrong: {wrong_syllables}, true: {true_sentence}, predicted: {predicted_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise factor: 6\n",
      "Average accuracy: 0.7241\n",
      "Total wrong syllables: 2257\n"
     ]
    }
   ],
   "source": [
    "# accuracy average and wrong syllables sum\n",
    "accuracy_avg = sum(result[2] for result in results) / len(results)\n",
    "wrong_syllables_sum = sum(result[3] for result in results)\n",
    "\n",
    "print(\"Noise factor:\", noise_factor)\n",
    "print(f\"Average accuracy: {accuracy_avg:.4f}\")\n",
    "print(f\"Total wrong syllables: {wrong_syllables_sum}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Noise level: 1\n",
    "- Average accuracy: 0.9776\n",
    "- Total wrong syllables: 1355\n",
    "---\n",
    "- Noise factor: 5\n",
    "- Average accuracy: 0.8453\n",
    "- Total wrong syllables: 2878\n",
    "---\n",
    "- Noise factor: 6\n",
    "- Average accuracy: 0.7241\n",
    "- Total wrong syllables: 2257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/{noise_factor}.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['True Sentence', 'Predicted Sentence', 'Accuracy', 'Wrong syllables'])\n",
    "    for row in results:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rosa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
