{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from transformers import ViTForImageClassification, SwinForImageClassification, Swinv2ForImageClassification, DeiTForImageClassification, BeitForImageClassification\n",
    "from transformers import AutoImageProcessor\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Swinv2ForImageClassification were not initialized from the model checkpoint at microsoft/swinv2-tiny-patch4-window16-256 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([36, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([36]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swin2 activated\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset path\n",
    "dataset_dir = '../../img_dataset_zoom'\n",
    "\n",
    "# select models\n",
    "vit     = False\n",
    "swin    = False \n",
    "swin2   = True\n",
    "deit    = False\n",
    "beit    = False\n",
    "\n",
    "if vit:\n",
    "    selected_model = 'vit'\n",
    "elif swin:\n",
    "    selected_model = 'swin'\n",
    "elif swin2:\n",
    "    selected_model = 'swin2'\n",
    "elif deit:\n",
    "    selected_model = 'deit'\n",
    "elif beit:\n",
    "    selected_model = 'beit'\n",
    "else:\n",
    "    raise ValueError('[ERROR] No selected model')\n",
    "\n",
    "# define models\n",
    "if swin:\n",
    "    model_name = 'microsoft/swin-tiny-patch4-window7-224'\n",
    "    processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "    model = SwinForImageClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=36,\n",
    "        ignore_mismatched_sizes=True  \n",
    "    )\n",
    "elif swin2:\n",
    "    model_name = 'microsoft/swinv2-tiny-patch4-window16-256'\n",
    "    processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "    model = Swinv2ForImageClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=36,\n",
    "        ignore_mismatched_sizes=True  \n",
    "    )\n",
    "elif vit:\n",
    "    model_name = 'google/vit-base-patch16-224-in21k'\n",
    "    processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "    model = ViTForImageClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=36,\n",
    "        # ignore_mismatched_sizes=True,\n",
    "    )\n",
    "elif deit:\n",
    "    model_name = 'facebook/deit-base-distilled-patch16-224'\n",
    "    processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "    model = DeiTForImageClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=36,\n",
    "        # ignore_mismatched_sizes=True\n",
    "    )\n",
    "elif beit:\n",
    "    model_name = 'microsoft/beit-base-patch16-224-pt22k-ft22k'  \n",
    "    processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "    model = BeitForImageClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=36,\n",
    "        ignore_mismatched_sizes=True  # Add this if necessary\n",
    "    )\n",
    "else:\n",
    "    raise ValueError('[ERROR] Select Your Model')\n",
    "\n",
    "# Define transformations\n",
    "if vit or swin or deit or beit:\n",
    "    print(\"vit/swin/deit/beit activated\")\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=processor.image_mean, std=processor.image_std),\n",
    "    ])\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=processor.image_mean, std=processor.image_std),\n",
    "    ])\n",
    "elif swin2:\n",
    "    print(\"swin2 activated\")\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=processor.image_mean, std=processor.image_std),\n",
    "    ])\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=processor.image_mean, std=processor.image_std),\n",
    "    ])\n",
    "else:\n",
    "    raise ValueError('[ERROR] Define any transformations')\n",
    "\n",
    "# Load the dataset\n",
    "full_dataset = ImageFolder(root=dataset_dir, transform=train_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 630, Validation set size: 180, Test set size: 90\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset per class into train and test sets\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract labels (targets) from the dataset\n",
    "targets = [sample[1] for sample in full_dataset.samples]  # Assuming ImageFolder's samples attribute\n",
    "\n",
    "# First split: Train and Temp (Val + Test)\n",
    "train_indices, temp_indices, y_train, y_temp = train_test_split(\n",
    "    range(len(targets)),\n",
    "    targets,\n",
    "    test_size=0.3,  # 30% of the data will go to val+test\n",
    "    stratify=targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: Validation and Test\n",
    "val_indices, test_indices, y_val, y_test = train_test_split(\n",
    "    temp_indices,\n",
    "    y_temp,\n",
    "    test_size=0.33,  # 33% of the temp data goes to test, resulting in 20% test of the total data\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create Subset datasets\n",
    "train_dataset = torch.utils.data.Subset(full_dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(full_dataset, val_indices)\n",
    "test_dataset = torch.utils.data.Subset(full_dataset, test_indices)\n",
    "\n",
    "# Apply test transforms to validation and test datasets\n",
    "val_dataset.dataset.transform = test_transforms\n",
    "test_dataset.dataset.transform = test_transforms\n",
    "\n",
    "# Print dataset sizes to verify\n",
    "print(f\"Train set size: {len(train_dataset)}, Validation set size: {len(val_dataset)}, Test set size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader    = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader      = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader     = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Swinv2ForImageClassification(\n",
       "  (swinv2): Swinv2Model(\n",
       "    (embeddings): Swinv2Embeddings(\n",
       "      (patch_embeddings): Swinv2PatchEmbeddings(\n",
       "        (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "      )\n",
       "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): Swinv2Encoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=96, out_features=96, bias=True)\n",
       "                  (key): Linear(in_features=96, out_features=96, bias=False)\n",
       "                  (value): Linear(in_features=96, out_features=96, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=96, out_features=384, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=384, out_features=96, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (downsample): Swinv2PatchMerging(\n",
       "            (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "            (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (key): Linear(in_features=192, out_features=192, bias=False)\n",
       "                  (value): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (downsample): Swinv2PatchMerging(\n",
       "            (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-5): 6 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (downsample): Swinv2PatchMerging(\n",
       "            (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=36, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the model to the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm  # For progress bars\n",
    "\n",
    "# Set up the optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', patience=5, factor=0.1, verbose=True)\n",
    "\n",
    "# Early stopping parameters\n",
    "best_val_accuracy = 0.0\n",
    "patience = 25  # Number of epochs to wait before early stopping\n",
    "epochs_no_improve = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Train Loss: 3.6176, Train Acc: 0.0175, Val Loss: 3.5809, Val Acc: 0.0278\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000, Train Loss: 3.5854, Train Acc: 0.0222, Val Loss: 3.5653, Val Acc: 0.0722\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000, Train Loss: 3.5351, Train Acc: 0.0603, Val Loss: 3.3756, Val Acc: 0.1056\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000, Train Loss: 3.2789, Train Acc: 0.0778, Val Loss: 3.1148, Val Acc: 0.1056\n",
      "No improvement in validation accuracy for 1 epochs.\n",
      "\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000, Train Loss: 2.8134, Train Acc: 0.1714, Val Loss: 2.5173, Val Acc: 0.1833\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 6/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000, Train Loss: 2.3708, Train Acc: 0.2667, Val Loss: 2.0218, Val Acc: 0.3333\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000, Train Loss: 1.8206, Train Acc: 0.4063, Val Loss: 1.5419, Val Acc: 0.4722\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000, Train Loss: 1.3928, Train Acc: 0.5508, Val Loss: 1.3022, Val Acc: 0.5556\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000, Train Loss: 1.1199, Train Acc: 0.6175, Val Loss: 1.1682, Val Acc: 0.6444\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 10/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000, Train Loss: 0.8345, Train Acc: 0.7175, Val Loss: 0.9372, Val Acc: 0.7056\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 11/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000, Train Loss: 0.6125, Train Acc: 0.8095, Val Loss: 0.6626, Val Acc: 0.7667\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000, Train Loss: 0.4822, Train Acc: 0.8556, Val Loss: 0.8012, Val Acc: 0.7333\n",
      "No improvement in validation accuracy for 1 epochs.\n",
      "\n",
      "Epoch 13/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000, Train Loss: 0.4580, Train Acc: 0.8508, Val Loss: 0.7043, Val Acc: 0.7556\n",
      "No improvement in validation accuracy for 2 epochs.\n",
      "\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000, Train Loss: 0.3451, Train Acc: 0.8873, Val Loss: 1.1313, Val Acc: 0.6833\n",
      "No improvement in validation accuracy for 3 epochs.\n",
      "\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000, Train Loss: 0.3787, Train Acc: 0.8825, Val Loss: 0.7117, Val Acc: 0.7667\n",
      "No improvement in validation accuracy for 4 epochs.\n",
      "\n",
      "Epoch 16/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/1000, Train Loss: 0.2241, Train Acc: 0.9333, Val Loss: 0.5582, Val Acc: 0.7722\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000, Train Loss: 0.2495, Train Acc: 0.9254, Val Loss: 0.8937, Val Acc: 0.7111\n",
      "No improvement in validation accuracy for 1 epochs.\n",
      "\n",
      "Epoch 18/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/1000, Train Loss: 0.2009, Train Acc: 0.9429, Val Loss: 0.6765, Val Acc: 0.8000\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 19/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000, Train Loss: 0.1987, Train Acc: 0.9333, Val Loss: 0.5940, Val Acc: 0.7833\n",
      "No improvement in validation accuracy for 1 epochs.\n",
      "\n",
      "Epoch 20/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000, Train Loss: 0.1658, Train Acc: 0.9571, Val Loss: 0.6864, Val Acc: 0.7722\n",
      "No improvement in validation accuracy for 2 epochs.\n",
      "\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/1000, Train Loss: 0.1319, Train Acc: 0.9667, Val Loss: 0.6526, Val Acc: 0.8000\n",
      "No improvement in validation accuracy for 3 epochs.\n",
      "\n",
      "Epoch 22/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mlogits, labels)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     24\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_loss = train_loss / total\n",
    "    train_accuracy = correct / total\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
    "            inputs, labels = batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            \n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss = val_loss / total\n",
    "    val_accuracy = correct / total\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
    "    \n",
    "    # Step the scheduler\n",
    "    scheduler.step(val_accuracy)\n",
    "    \n",
    "    # Check for improvement\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), f'best_model_zoom_{selected_model}.pth')\n",
    "        print(\"Validation accuracy improved, model saved.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement in validation accuracy for {epochs_no_improve} epochs.\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    1.0000    0.8000         2\n",
      "           1     1.0000    0.6667    0.8000         3\n",
      "           2     0.7500    1.0000    0.8571         3\n",
      "           3     1.0000    0.6667    0.8000         3\n",
      "           4     0.5000    1.0000    0.6667         2\n",
      "           5     1.0000    0.5000    0.6667         2\n",
      "           6     1.0000    1.0000    1.0000         3\n",
      "           7     1.0000    1.0000    1.0000         3\n",
      "           8     1.0000    1.0000    1.0000         2\n",
      "           9     1.0000    1.0000    1.0000         2\n",
      "          10     1.0000    1.0000    1.0000         3\n",
      "          11     0.6667    0.6667    0.6667         3\n",
      "          12     1.0000    0.5000    0.6667         2\n",
      "          13     1.0000    1.0000    1.0000         2\n",
      "          14     1.0000    1.0000    1.0000         3\n",
      "          15     0.6667    1.0000    0.8000         2\n",
      "          16     1.0000    1.0000    1.0000         2\n",
      "          17     0.6667    1.0000    0.8000         2\n",
      "          18     1.0000    0.3333    0.5000         3\n",
      "          19     1.0000    1.0000    1.0000         2\n",
      "          20     0.7500    1.0000    0.8571         3\n",
      "          21     1.0000    1.0000    1.0000         2\n",
      "          22     1.0000    0.6667    0.8000         3\n",
      "          23     1.0000    0.6667    0.8000         3\n",
      "          24     0.6667    0.6667    0.6667         3\n",
      "          25     0.7500    1.0000    0.8571         3\n",
      "          26     1.0000    1.0000    1.0000         2\n",
      "          27     1.0000    1.0000    1.0000         3\n",
      "          28     1.0000    0.6667    0.8000         3\n",
      "          29     1.0000    0.5000    0.6667         2\n",
      "          30     1.0000    1.0000    1.0000         2\n",
      "          31     1.0000    0.5000    0.6667         2\n",
      "          32     1.0000    1.0000    1.0000         3\n",
      "          33     0.5000    0.6667    0.5714         3\n",
      "          34     0.6667    1.0000    0.8000         2\n",
      "          35     0.6667    1.0000    0.8000         2\n",
      "\n",
      "    accuracy                         0.8444        90\n",
      "   macro avg     0.8866    0.8519    0.8419        90\n",
      "weighted avg     0.8880    0.8444    0.8399        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing the model and generating a classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the best model \n",
    "model.load_state_dict(torch.load(f'best_model_zoom_{selected_model}.pth'))\n",
    "\n",
    "# Collect all predictions and labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(all_labels, all_preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
