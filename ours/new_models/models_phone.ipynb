{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from transformers import ViTForImageClassification, SwinForImageClassification, Swinv2ForImageClassification, DeiTForImageClassification, BeitForImageClassification\n",
    "from transformers import AutoImageProcessor\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Swinv2ForImageClassification were not initialized from the model checkpoint at microsoft/swinv2-tiny-patch4-window16-256 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([36, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([36]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swin2 activated\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset path\n",
    "dataset_dir = '../../img_dataset_phone'\n",
    "\n",
    "# select models\n",
    "vit     = False\n",
    "swin    = False \n",
    "swin2   = True\n",
    "deit    = False\n",
    "beit    = False\n",
    "\n",
    "if vit:\n",
    "    selected_model = 'vit'\n",
    "elif swin:\n",
    "    selected_model = 'swin'\n",
    "elif swin2:\n",
    "    selected_model = 'swin2'\n",
    "elif deit:\n",
    "    selected_model = 'deit'\n",
    "elif beit:\n",
    "    selected_model = 'beit'\n",
    "else:\n",
    "    raise ValueError('[ERROR] No selected model')\n",
    "\n",
    "# define models\n",
    "if swin:\n",
    "    model_name = 'microsoft/swin-tiny-patch4-window7-224'\n",
    "    processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "    model = SwinForImageClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=36,\n",
    "        ignore_mismatched_sizes=True  \n",
    "    )\n",
    "elif swin2:\n",
    "    model_name = 'microsoft/swinv2-tiny-patch4-window16-256'\n",
    "    processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "    model = Swinv2ForImageClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=36,\n",
    "        ignore_mismatched_sizes=True  \n",
    "    )\n",
    "elif vit:\n",
    "    model_name = 'google/vit-base-patch16-224-in21k'\n",
    "    processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "    model = ViTForImageClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=36,\n",
    "        # ignore_mismatched_sizes=True,\n",
    "    )\n",
    "elif deit:\n",
    "    model_name = 'facebook/deit-base-distilled-patch16-224'\n",
    "    processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "    model = DeiTForImageClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=36,\n",
    "        # ignore_mismatched_sizes=True\n",
    "    )\n",
    "elif beit:\n",
    "    model_name = 'microsoft/beit-base-patch16-224-pt22k-ft22k'  \n",
    "    processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "    model = BeitForImageClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=36,\n",
    "        ignore_mismatched_sizes=True  # Add this if necessary\n",
    "    )\n",
    "else:\n",
    "    raise ValueError('[ERROR] Select Your Model')\n",
    "\n",
    "# Define transformations\n",
    "if vit or swin or deit or beit:\n",
    "    print(\"vit/swin/deit/beit activated\")\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=processor.image_mean, std=processor.image_std),\n",
    "    ])\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=processor.image_mean, std=processor.image_std),\n",
    "    ])\n",
    "elif swin2:\n",
    "    print(\"swin2 activated\")\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=processor.image_mean, std=processor.image_std),\n",
    "    ])\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=processor.image_mean, std=processor.image_std),\n",
    "    ])\n",
    "else:\n",
    "    raise ValueError('[ERROR] Define any transformations')\n",
    "\n",
    "# Load the dataset\n",
    "full_dataset = ImageFolder(root=dataset_dir, transform=train_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 630, Validation set size: 180, Test set size: 90\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset per class into train and test sets\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract labels (targets) from the dataset\n",
    "targets = [sample[1] for sample in full_dataset.samples]  # Assuming ImageFolder's samples attribute\n",
    "\n",
    "# First split: Train and Temp (Val + Test)\n",
    "train_indices, temp_indices, y_train, y_temp = train_test_split(\n",
    "    range(len(targets)),\n",
    "    targets,\n",
    "    test_size=0.3,  # 30% of the data will go to val+test\n",
    "    stratify=targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: Validation and Test\n",
    "val_indices, test_indices, y_val, y_test = train_test_split(\n",
    "    temp_indices,\n",
    "    y_temp,\n",
    "    test_size=0.33,  # 33% of the temp data goes to test, resulting in 20% test of the total data\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create Subset datasets\n",
    "train_dataset = torch.utils.data.Subset(full_dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(full_dataset, val_indices)\n",
    "test_dataset = torch.utils.data.Subset(full_dataset, test_indices)\n",
    "\n",
    "# Apply test transforms to validation and test datasets\n",
    "val_dataset.dataset.transform = test_transforms\n",
    "test_dataset.dataset.transform = test_transforms\n",
    "\n",
    "# Print dataset sizes to verify\n",
    "print(f\"Train set size: {len(train_dataset)}, Validation set size: {len(val_dataset)}, Test set size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader    = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader      = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader     = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Swinv2ForImageClassification(\n",
       "  (swinv2): Swinv2Model(\n",
       "    (embeddings): Swinv2Embeddings(\n",
       "      (patch_embeddings): Swinv2PatchEmbeddings(\n",
       "        (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "      )\n",
       "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): Swinv2Encoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=96, out_features=96, bias=True)\n",
       "                  (key): Linear(in_features=96, out_features=96, bias=False)\n",
       "                  (value): Linear(in_features=96, out_features=96, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=96, out_features=384, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=384, out_features=96, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (downsample): Swinv2PatchMerging(\n",
       "            (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "            (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (key): Linear(in_features=192, out_features=192, bias=False)\n",
       "                  (value): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (downsample): Swinv2PatchMerging(\n",
       "            (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-5): 6 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (downsample): Swinv2PatchMerging(\n",
       "            (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=36, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the model to the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm  # For progress bars\n",
    "\n",
    "# Set up the optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', patience=5, factor=0.1, verbose=True)\n",
    "\n",
    "# Early stopping parameters\n",
    "best_val_accuracy = 0.0\n",
    "patience = 25  # Number of epochs to wait before early stopping\n",
    "epochs_no_improve = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Train Loss: 3.6132, Train Acc: 0.0206, Val Loss: 3.5823, Val Acc: 0.0278\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000, Train Loss: 3.5907, Train Acc: 0.0159, Val Loss: 3.5795, Val Acc: 0.0167\n",
      "No improvement in validation accuracy for 1 epochs.\n",
      "\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000, Train Loss: 3.5866, Train Acc: 0.0222, Val Loss: 3.5644, Val Acc: 0.0500\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000, Train Loss: 3.5188, Train Acc: 0.0698, Val Loss: 3.2581, Val Acc: 0.0944\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000, Train Loss: 3.1704, Train Acc: 0.1111, Val Loss: 2.5052, Val Acc: 0.2944\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 6/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000, Train Loss: 2.3571, Train Acc: 0.2730, Val Loss: 1.5280, Val Acc: 0.5056\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000, Train Loss: 1.6139, Train Acc: 0.4778, Val Loss: 1.1065, Val Acc: 0.6444\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000, Train Loss: 1.1111, Train Acc: 0.6286, Val Loss: 0.9155, Val Acc: 0.6611\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000, Train Loss: 0.6498, Train Acc: 0.7873, Val Loss: 0.7273, Val Acc: 0.7611\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 10/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000, Train Loss: 0.4703, Train Acc: 0.8524, Val Loss: 0.9609, Val Acc: 0.7167\n",
      "No improvement in validation accuracy for 1 epochs.\n",
      "\n",
      "Epoch 11/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000, Train Loss: 0.5068, Train Acc: 0.8381, Val Loss: 0.6670, Val Acc: 0.8222\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000, Train Loss: 0.3699, Train Acc: 0.8873, Val Loss: 0.5661, Val Acc: 0.8278\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 13/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000, Train Loss: 0.3071, Train Acc: 0.9079, Val Loss: 0.5143, Val Acc: 0.8167\n",
      "No improvement in validation accuracy for 1 epochs.\n",
      "\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000, Train Loss: 0.2071, Train Acc: 0.9413, Val Loss: 0.4846, Val Acc: 0.8500\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000, Train Loss: 0.1770, Train Acc: 0.9460, Val Loss: 0.3501, Val Acc: 0.8944\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 16/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/1000, Train Loss: 0.1657, Train Acc: 0.9619, Val Loss: 0.3565, Val Acc: 0.8833\n",
      "No improvement in validation accuracy for 1 epochs.\n",
      "\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000, Train Loss: 0.1130, Train Acc: 0.9730, Val Loss: 0.5051, Val Acc: 0.8556\n",
      "No improvement in validation accuracy for 2 epochs.\n",
      "\n",
      "Epoch 18/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/1000, Train Loss: 0.1685, Train Acc: 0.9381, Val Loss: 0.3653, Val Acc: 0.9000\n",
      "Validation accuracy improved, model saved.\n",
      "\n",
      "Epoch 19/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000, Train Loss: 0.1755, Train Acc: 0.9460, Val Loss: 0.3847, Val Acc: 0.8889\n",
      "No improvement in validation accuracy for 1 epochs.\n",
      "\n",
      "Epoch 20/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000, Train Loss: 0.1013, Train Acc: 0.9698, Val Loss: 0.3216, Val Acc: 0.9000\n",
      "No improvement in validation accuracy for 2 epochs.\n",
      "\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 30/40 [00:29<00:07,  1.28it/s]"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_loss = train_loss / total\n",
    "    train_accuracy = correct / total\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
    "            inputs, labels = batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            \n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss = val_loss / total\n",
    "    val_accuracy = correct / total\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
    "    \n",
    "    # Step the scheduler\n",
    "    scheduler.step(val_accuracy)\n",
    "    \n",
    "    # Check for improvement\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), f'best_model_phone_{selected_model}.pth')\n",
    "        print(\"Validation accuracy improved, model saved.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement in validation accuracy for {epochs_no_improve} epochs.\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000         2\n",
      "           1     1.0000    1.0000    1.0000         3\n",
      "           2     1.0000    1.0000    1.0000         3\n",
      "           3     1.0000    1.0000    1.0000         3\n",
      "           4     1.0000    1.0000    1.0000         2\n",
      "           5     1.0000    1.0000    1.0000         2\n",
      "           6     1.0000    1.0000    1.0000         3\n",
      "           7     1.0000    0.3333    0.5000         3\n",
      "           8     1.0000    0.5000    0.6667         2\n",
      "           9     0.6667    1.0000    0.8000         2\n",
      "          10     1.0000    1.0000    1.0000         3\n",
      "          11     1.0000    1.0000    1.0000         3\n",
      "          12     1.0000    1.0000    1.0000         2\n",
      "          13     0.6667    1.0000    0.8000         2\n",
      "          14     1.0000    1.0000    1.0000         3\n",
      "          15     1.0000    1.0000    1.0000         2\n",
      "          16     1.0000    1.0000    1.0000         2\n",
      "          17     1.0000    1.0000    1.0000         2\n",
      "          18     0.7500    1.0000    0.8571         3\n",
      "          19     1.0000    1.0000    1.0000         2\n",
      "          20     1.0000    1.0000    1.0000         3\n",
      "          21     1.0000    1.0000    1.0000         2\n",
      "          22     1.0000    1.0000    1.0000         3\n",
      "          23     1.0000    1.0000    1.0000         3\n",
      "          24     0.7500    1.0000    0.8571         3\n",
      "          25     1.0000    1.0000    1.0000         3\n",
      "          26     1.0000    1.0000    1.0000         2\n",
      "          27     1.0000    1.0000    1.0000         3\n",
      "          28     1.0000    0.6667    0.8000         3\n",
      "          29     1.0000    1.0000    1.0000         2\n",
      "          30     0.0000    0.0000    0.0000         2\n",
      "          31     1.0000    1.0000    1.0000         2\n",
      "          32     1.0000    1.0000    1.0000         3\n",
      "          33     1.0000    1.0000    1.0000         3\n",
      "          34     0.5000    1.0000    0.6667         2\n",
      "          35     1.0000    1.0000    1.0000         2\n",
      "\n",
      "    accuracy                         0.9333        90\n",
      "   macro avg     0.9259    0.9306    0.9152        90\n",
      "weighted avg     0.9352    0.9333    0.9212        90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\user\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Testing the model and generating a classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the best model \n",
    "model.load_state_dict(torch.load(f'best_model_phone_{selected_model}.pth'))\n",
    "\n",
    "# Collect all predictions and labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(all_labels, all_preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
