{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import difflib\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"input_batches\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messages(sentence, examples):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in correcting typos in sentences.\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "Here are examples of sentences with typos; learn from them:\n",
    "\n",
    "{examples}\n",
    "Now, please correct this sentence and output only the corrected version with no additional text:\n",
    "\n",
    "{target_sentence}\n",
    "        \"\"\".format(target_sentence=sentence, examples=examples)},\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2816753/1033020455.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for index, row in tqdm(df.iterrows(), total=total):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e0f9e6218e4a338894b953ffceb02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved input_batches/phone_gpt4o_nf_noise_0.012.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2816753/1033020455.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for index, row in tqdm(df.iterrows(), total=total):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a94fe278c674979a21dad990c25007e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved input_batches/phone_gpt4o_nf_noise_0.024.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2816753/1033020455.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for index, row in tqdm(df.iterrows(), total=total):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c47babd70b4652964ea82c0abe84f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved input_batches/phone_gpt4o_nf_noise_0.06.jsonl\n"
     ]
    }
   ],
   "source": [
    "# create input batches (jsonl)\n",
    "\n",
    "NFs = [\n",
    "    \"noise_0.012\",\n",
    "    \"noise_0.024\",\n",
    "    \"noise_0.06\",\n",
    "]\n",
    "\n",
    "for nf in NFs:\n",
    "    df = pd.read_csv(f\"results/{nf}.csv\")\n",
    "    examples = \"\"\n",
    "    total=len(df)\n",
    "    jsonl_file = f\"input_batches/phone_gpt4o_nf_{nf}.jsonl\"\n",
    "    jsonl = []\n",
    "\n",
    "    for i in range(2):\n",
    "        examples += f\"\\tsentence: {df['Predicted Sentence'][i]}\\n\"\n",
    "        examples += f\"\\tcorrected: {df['True Sentence'][i]}\\n\\n\"\n",
    "        \n",
    "    for index, row in tqdm(df.iterrows(), total=total):\n",
    "        predicted_sentence = row['Predicted Sentence']\n",
    "        messages = get_messages(predicted_sentence, examples)\n",
    "        # create openai request\n",
    "        prompt = {\n",
    "            \"custom_id\": f\"{index}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": \"gpt-4o\",\n",
    "                \"messages\": messages,\n",
    "                \"max_tokens\": 1000,\n",
    "            }\n",
    "        }\n",
    "        jsonl.append(json.dumps(prompt))\n",
    "    \n",
    "    with open(jsonl_file, \"w\") as f:\n",
    "        for line in jsonl:\n",
    "            f.write(line + \"\\n\")\n",
    "    print(f\"Saved {jsonl_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_openai_batch_output(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        responses = [json.loads(line) for line in file]\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_sentence_from_openai(responses, index):\n",
    "    # Find the response corresponding to the current index\n",
    "    response = responses[index]\n",
    "    llm_sentence = response['response']['body']['choices'][0]['message']['content']\n",
    "    return llm_sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_postprocess(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    # remove all non a-z0-9 \n",
    "    sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence):\n",
    "    # Character-level accuracy using SequenceMatcher\n",
    "    char_matcher = difflib.SequenceMatcher(None, true_sentence, predicted_sentence)\n",
    "    accuracy = char_matcher.ratio()\n",
    "    \n",
    "    # Word-level wrong syllable count using SequenceMatcher on word lists\n",
    "    true_words = true_sentence.split()\n",
    "    predicted_words = predicted_sentence.split()\n",
    "    word_matcher = difflib.SequenceMatcher(None, true_words, predicted_words)\n",
    "    \n",
    "    # Calculate wrong syllables based on insert, delete, and replace operations\n",
    "    wrong_syllables = sum(1 for tag, _, _, _, _ in word_matcher.get_opcodes() if tag in ('insert', 'delete', 'replace'))\n",
    "    \n",
    "    return accuracy, wrong_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3147465/4249433214.py:26: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for index, row in tqdm(df.iterrows(), total=total):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3d68ff82da45a9a14248c935d59816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LLM Auto] Index: 0 of 1000\n",
      "[LLM Auto] CoAtNet 0.9326923076923077 4\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 100 of 1000\n",
      "[LLM Auto] CoAtNet 0.9452054794520548 3\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 200 of 1000\n",
      "[LLM Auto] CoAtNet 0.9523809523809523 1\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 300 of 1000\n",
      "[LLM Auto] CoAtNet 0.972972972972973 2\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 400 of 1000\n",
      "[LLM Auto] CoAtNet 1.0 0\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 500 of 1000\n",
      "[LLM Auto] CoAtNet 0.8888888888888888 4\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 600 of 1000\n",
      "[LLM Auto] CoAtNet 0.9743589743589743 2\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 700 of 1000\n",
      "[LLM Auto] CoAtNet 0.9574468085106383 3\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 800 of 1000\n",
      "[LLM Auto] CoAtNet 0.9418604651162791 2\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 900 of 1000\n",
      "[LLM Auto] CoAtNet 0.9444444444444444 2\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Model: GPT-4o\n",
      "[LLM Auto] NF noise_0.012\n",
      "[LLM Auto] LLM Average Accuracy: 0.9978416153142287\n",
      "[LLM Auto] LLM Sum of Wrong Syllables: 134\n",
      "[LLM Auto] ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3147465/4249433214.py:26: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for index, row in tqdm(df.iterrows(), total=total):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49777db0416a4167a1fac73adae73cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LLM Auto] Index: 0 of 1000\n",
      "[LLM Auto] CoAtNet 0.8269230769230769 4\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 100 of 1000\n",
      "[LLM Auto] CoAtNet 0.8356164383561644 7\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 200 of 1000\n",
      "[LLM Auto] CoAtNet 0.8809523809523809 4\n",
      "[LLM Auto] LLM 0.9761904761904762 1\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 300 of 1000\n",
      "[LLM Auto] CoAtNet 0.9054054054054054 4\n",
      "[LLM Auto] LLM 0.9864864864864865 1\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 400 of 1000\n",
      "[LLM Auto] CoAtNet 0.8333333333333334 5\n",
      "[LLM Auto] LLM 0.9861111111111112 1\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 500 of 1000\n",
      "[LLM Auto] CoAtNet 0.873015873015873 3\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 600 of 1000\n",
      "[LLM Auto] CoAtNet 0.8589743589743589 3\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 700 of 1000\n",
      "[LLM Auto] CoAtNet 0.8829787234042553 3\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 800 of 1000\n",
      "[LLM Auto] CoAtNet 0.872093023255814 4\n",
      "[LLM Auto] LLM 0.9883720930232558 1\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 900 of 1000\n",
      "[LLM Auto] CoAtNet 0.8555555555555555 3\n",
      "[LLM Auto] LLM 0.972972972972973 1\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Model: GPT-4o\n",
      "[LLM Auto] NF noise_0.024\n",
      "[LLM Auto] LLM Average Accuracy: 0.9884160961775788\n",
      "[LLM Auto] LLM Sum of Wrong Syllables: 468\n",
      "[LLM Auto] ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3147465/4249433214.py:26: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for index, row in tqdm(df.iterrows(), total=total):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fab3fa0dd514978ab236b21e6f7edb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LLM Auto] Index: 0 of 1000\n",
      "[LLM Auto] CoAtNet 0.6634615384615384 3\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 100 of 1000\n",
      "[LLM Auto] CoAtNet 0.6712328767123288 2\n",
      "[LLM Auto] LLM 0.993103448275862 1\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 200 of 1000\n",
      "[LLM Auto] CoAtNet 0.6547619047619048 2\n",
      "[LLM Auto] LLM 0.9761904761904762 1\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 300 of 1000\n",
      "[LLM Auto] CoAtNet 0.6351351351351351 3\n",
      "[LLM Auto] LLM 0.96 2\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 400 of 1000\n",
      "[LLM Auto] CoAtNet 0.6805555555555556 2\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 500 of 1000\n",
      "[LLM Auto] CoAtNet 0.6825396825396826 3\n",
      "[LLM Auto] LLM 0.7761194029850746 2\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 600 of 1000\n",
      "[LLM Auto] CoAtNet 0.6666666666666666 1\n",
      "[LLM Auto] LLM 0.9615384615384616 1\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 700 of 1000\n",
      "[LLM Auto] CoAtNet 0.7127659574468085 2\n",
      "[LLM Auto] LLM 1.0 0\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 800 of 1000\n",
      "[LLM Auto] CoAtNet 0.6976744186046512 3\n",
      "[LLM Auto] LLM 0.7978142076502732 3\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Index: 900 of 1000\n",
      "[LLM Auto] CoAtNet 0.6777777777777778 2\n",
      "[LLM Auto] LLM 0.9010989010989011 1\n",
      "[LLM Auto] ==========\n",
      "[LLM Auto] Model: GPT-4o\n",
      "[LLM Auto] NF noise_0.06\n",
      "[LLM Auto] LLM Average Accuracy: 0.9037422833557085\n",
      "[LLM Auto] LLM Sum of Wrong Syllables: 1450\n",
      "[LLM Auto] ===\n"
     ]
    }
   ],
   "source": [
    "# prepare the output batches\n",
    "output_batches_dir = \"output_batches\"\n",
    "name_prefix = \"phone_gpt4o_nf_\"\n",
    "output_dir = \"results/gpt-4o\"\n",
    "NFs = [\n",
    "    \"noise_0.012\",\n",
    "    \"noise_0.024\",\n",
    "    \"noise_0.06\",\n",
    "]\n",
    "\n",
    "\n",
    "for nf in NFs:\n",
    "    df = pd.read_csv(f\"results/{nf}.csv\")\n",
    "    responses = load_openai_batch_output(f'{output_batches_dir}/{name_prefix}{nf}.jsonl')\n",
    "    examples = \"\"\n",
    "\n",
    "    for i in range(2):\n",
    "        examples += f\"\\tsentence: {df['Predicted Sentence'][i]}\\n\"\n",
    "        examples += f\"\\tcorrected: {df['True Sentence'][i]}\\n\\n\"\n",
    "\n",
    "    llm_accs = []\n",
    "    llm_ws = []\n",
    "    llm_sen = []\n",
    "    total = len(df)\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=total):\n",
    "        should_print = index % 100 == 0\n",
    "        predicted_sentence = row['Predicted Sentence']\n",
    "        true_sentence = row['True Sentence']\n",
    "        accuracy, wrong_syllables = compute_accuracy_and_wrong_syllables(true_sentence, predicted_sentence)\n",
    "        \n",
    "        if should_print:\n",
    "            print(f\"[LLM Auto] Index: {index} of {total}\")\n",
    "            print(\"[LLM Auto] CoAtNet\", accuracy, wrong_syllables)\n",
    "\n",
    "        llm_sentence = get_llm_sentence_from_openai(responses, index)\n",
    "        llm_sentence = llm_postprocess(llm_sentence)\n",
    "        accuracy, wrong_syllables = compute_accuracy_and_wrong_syllables(true_sentence, llm_sentence)\n",
    "        \n",
    "        if should_print:\n",
    "            print(\"[LLM Auto] LLM\", accuracy, wrong_syllables)\n",
    "            print(\"[LLM Auto] ==========\")\n",
    "        \n",
    "        llm_sen.append(llm_sentence)\n",
    "        llm_accs.append(accuracy)\n",
    "        llm_ws.append(wrong_syllables)\n",
    "\n",
    "    df['LLM Sentence'] = llm_sen\n",
    "    df['LLM Accuracy'] = llm_accs\n",
    "    df['LLM Wrong syllables'] = llm_ws\n",
    "\n",
    "    llm_avg_accuracy = sum(llm_accs) / len(llm_accs)\n",
    "    llm_sum_wrong_syllables = sum(llm_ws)\n",
    "\n",
    "    print(f\"[LLM Auto] Model: GPT-4o\")\n",
    "    print(f\"[LLM Auto] NF {nf}\")\n",
    "    print(f\"[LLM Auto] LLM Average Accuracy: {llm_avg_accuracy}\")\n",
    "    print(f\"[LLM Auto] LLM Sum of Wrong Syllables: {llm_sum_wrong_syllables}\")\n",
    "    print(\"[LLM Auto] ===\")\n",
    "    \n",
    "    df.to_csv(f'{output_dir}/{nf}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
