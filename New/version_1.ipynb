{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinhyunpark/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import ignite.metrics\n",
    "import ignite.contrib.handlers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "import librosa.display as ld\n",
    "import pandas as pd\n",
    "import noisereduce as nr\n",
    "import soundfile as sf\n",
    "import pickle\n",
    "\n",
    "from torchinfo import summary\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import wavfile\n",
    "from functools import reduce\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64\n",
    "NUM_CLASSES = 36 # 26 + 10\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 5e-4\n",
    "WEIGHT_DECAY = 1e-1\n",
    "EPOCHS = 1100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolator(signal, sample_rate, size, scan, before, after, threshold, show=False):\n",
    "    strokes = []\n",
    "    # -- signal'\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(signal, sr=sample_rate)\n",
    "    fft = librosa.stft(signal, n_fft=size, hop_length=scan)\n",
    "    energy = np.abs(np.sum(fft, axis=0)).astype(float)\n",
    "    # norm = np.linalg.norm(energy)\n",
    "    # energy = energy/norm\n",
    "    # -- energy'\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(energy)\n",
    "    threshed = energy > threshold\n",
    "    # -- peaks'\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(threshed.astype(float))\n",
    "    peaks = np.where(threshed == True)[0]\n",
    "    peak_count = len(peaks)\n",
    "    prev_end = sample_rate*0.1*(-1)\n",
    "    # '-- isolating keystrokes'\n",
    "    for i in range(peak_count):\n",
    "        this_peak = peaks[i]\n",
    "        timestamp = (this_peak*scan) + size//2\n",
    "        if timestamp > prev_end + (0.1*sample_rate):\n",
    "            keystroke = signal[timestamp-before:timestamp+after]\n",
    "            strokes.append(torch.tensor(keystroke)[None, :])\n",
    "            if show:\n",
    "                plt.figure(figsize=(7, 2))\n",
    "                librosa.display.waveshow(keystroke, sr=sample_rate)\n",
    "            prev_end = timestamp+after\n",
    "    return strokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_FILE = '../dataset/Zoom/'\n",
    "keys_s = '1234567890qwertyuiopasdfghjklzxcvbnm'\n",
    "labels = list(keys_s)\n",
    "keys = [k + '.wav' for k in labels]\n",
    "data_dict = {'Key':[], 'File':[]}\n",
    "\n",
    "for i, File in enumerate(keys):\n",
    "    loc = AUDIO_FILE + File\n",
    "    samples, sample_rate = librosa.load(loc, sr=None)\n",
    "    #samples = samples[round(1*sample_rate):]\n",
    "    strokes = []\n",
    "    prom = 0.06\n",
    "    step = 0.005\n",
    "    while not len(strokes) == 25:\n",
    "        strokes = isolator(samples[1*sample_rate:], sample_rate, 48, 24, 2400, 12000, prom, False)\n",
    "        if len(strokes) < 25:\n",
    "            prom -= step\n",
    "        if len(strokes) > 25:\n",
    "            prom += step\n",
    "        if prom <= 0:\n",
    "            print('-- not possible for: ',File)\n",
    "            break\n",
    "        step = step*0.99\n",
    "    label = [labels[i]]*len(strokes)\n",
    "    data_dict['Key'] += label\n",
    "    data_dict['File'] += strokes\n",
    "\n",
    "df = pd.DataFrame(data_dict)\n",
    "mapper = {}\n",
    "counter = 0\n",
    "for l in df['Key']:\n",
    "    if not l in mapper:\n",
    "        mapper[l] = counter\n",
    "        counter += 1\n",
    "df.replace({'Key': mapper}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Rate --> \n",
      " 32000\n",
      "--------------------------------------------------\n",
      "data_frame.head() --> \n",
      "   Key                                               File\n",
      "0   0  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...\n",
      "1   0  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...\n",
      "2   0  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...\n",
      "3   0  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...\n",
      "4   0  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Key     900 non-null    object\n",
      " 1   File    900 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 14.2+ KB\n",
      "data_frame.info() --> \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample Rate --> \\n\", sample_rate)\n",
    "sr = sample_rate\n",
    "print(\"-\"*50)\n",
    "print(\"data_frame.head() --> \\n\", df.head())\n",
    "print(\"-\"*50)\n",
    "print(\"data_frame.info() --> \\n\", df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_name, transform = None, aug = None):\n",
    "        df = file_name\n",
    "        self.transform = transform\n",
    "        self.aug = aug\n",
    "        self.labels = df['Key']\n",
    "        self.values = df['File']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels.iloc[index]\n",
    "        value = self.values.iloc[index]\n",
    "        waveform = self.values.iloc[index]\n",
    "        label = self.labels.iloc[index]\n",
    "        if self.transform:\n",
    "            waveform = waveform.numpy()\n",
    "            waveform = waveform.flatten()\n",
    "            waveform = self.transform(waveform)\n",
    "        if self.aug:\n",
    "            waveform = self.aug(waveform)\n",
    "        return waveform, label\n",
    "\n",
    "class ToMelSpectrogram:\n",
    "    def __call__(self, samples):\n",
    "#         samples = np.array(samples)\n",
    "        spec = librosa.feature.melspectrogram(y = samples, sr = sr, n_mels=64, n_fft=1024, hop_length=226)\n",
    "        return librosa.power_to_db(spec)\n",
    "\n",
    "class TimeShifting():\n",
    "    def __call__(self, samples):\n",
    "        samples = samples.numpy()\n",
    "        samples = samples.flatten()\n",
    "        \n",
    "        shift = int(len(samples) * 0.4)\n",
    "        random_shift =random.randint(0, shift)\n",
    "        data_roll = np.roll(samples, random_shift)\n",
    "        return data_roll\n",
    "    \n",
    "class SpecAugment():\n",
    "    def __call__(self, samples):\n",
    "        num_mask = 2\n",
    "        freq_masking_max_percentage=0.10\n",
    "        time_masking_max_percentage=0.10\n",
    "        spec = samples.copy()\n",
    "        mean_value = spec.mean()\n",
    "        for i in range(num_mask):\n",
    "            all_frames_num, all_freqs_num = spec.shape[1], spec.shape[1] \n",
    "            freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n",
    "\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            spec[:, f0:f0 + num_freqs_to_mask] = mean_value\n",
    "\n",
    "            time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            spec[t0:t0 + num_frames_to_mask, :] = mean_value\n",
    "        return spec\n",
    "\n",
    "aug = Compose([\n",
    "    TimeShifting(),\n",
    "    ToMelSpectrogram(),\n",
    "    SpecAugment(),\n",
    "    ToTensor()\n",
    "    ])\n",
    "\n",
    "transform = Compose([\n",
    "    ToMelSpectrogram(),\n",
    "    ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train, aug = aug)\n",
    "val_dataset = MyDataset(test, transform = transform)\n",
    "train_loader = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x173e32e10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.imshow(train_dataset[0][0][0], cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {'epochs':[], 'train_data_loss':[], \"train_data_acc\":[], 'val_data_acc':[], 'val_data_loss':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_linear(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None: nn.init.zeros_(m.bias)\n",
    "\n",
    "class Partial:\n",
    "    def __init__(self, module, *args, **kwargs):\n",
    "        self.module = module\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, *args_c, **kwargs_c):\n",
    "        return self.module(*args_c, *self.args, **kwargs_c, **self.kwargs)\n",
    "\n",
    "class LayerNormChannels(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, -1)\n",
    "        x = self.norm(x)\n",
    "        x = x.transpose(-1, 1)\n",
    "        return x\n",
    "    \n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, *layers, shortcut=None):\n",
    "        super().__init__()\n",
    "        self.shortcut = nn.Identity() if shortcut is None else shortcut\n",
    "        self.residual = nn.Sequential(*layers)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.shortcut(x) + self.gamma * self.residual(x)\n",
    "    \n",
    "class ConvBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, groups=1):\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        super().__init__(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding,\n",
    "                      groups=groups, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "def get_shortcut(in_channels, out_channels, stride):\n",
    "    if (in_channels == out_channels and stride == 1):\n",
    "        shortcut = nn.Identity()\n",
    "    else:\n",
    "        shortcut = nn.Conv2d(in_channels, out_channels, 1)\n",
    "\n",
    "    if stride > 1:\n",
    "        shortcut = nn.Sequential(nn.MaxPool2d(stride), shortcut)\n",
    "    \n",
    "    return shortcut\n",
    "\n",
    "class SqueezeExciteBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=4):\n",
    "        super().__init__()\n",
    "        self.out_channels = channels\n",
    "        channels_r = channels // reduction\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels_r, kernel_size=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(channels_r, channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x * self.se(x)\n",
    "    \n",
    "class MBConv(Residual):\n",
    "    def __init__(self, in_channels, out_channels, shape, kernel_size=3, stride=1, expansion_factor=4):\n",
    "        mid_channels = in_channels * expansion_factor\n",
    "        super().__init__(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.GELU(),\n",
    "            ConvBlock(in_channels, mid_channels, 1), # Pointwise\n",
    "            ConvBlock(mid_channels, mid_channels, kernel_size, stride=stride, groups=mid_channels), # Depthwise\n",
    "            SqueezeExciteBlock(mid_channels),\n",
    "            nn.Conv2d(mid_channels, out_channels, 1), # Pointwise\n",
    "            shortcut = get_shortcut(in_channels, out_channels, stride)\n",
    "        )\n",
    "\n",
    "class SelfAttention2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, head_channels, shape, p_drop=0.):\n",
    "        super().__init__()\n",
    "        self.heads = out_channels // head_channels\n",
    "        self.head_channels = head_channels\n",
    "        self.scale = head_channels**-0.5\n",
    "        \n",
    "        self.to_keys = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.to_queries = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.to_values = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.unifyheads = nn.Conv2d(out_channels, out_channels, 1)\n",
    "        \n",
    "        height, width = shape\n",
    "        self.pos_enc = nn.Parameter(torch.randn(self.heads, (2 * height - 1) * (2 * width - 1)))\n",
    "        self.register_buffer(\"relative_indices\", self.get_indices(height, width))\n",
    "\n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, _, h, w = x.shape\n",
    "        \n",
    "        keys = self.to_keys(x).view(b, self.heads, self.head_channels, -1)\n",
    "        values = self.to_values(x).view(b, self.heads, self.head_channels, -1)\n",
    "        queries = self.to_queries(x).view(b, self.heads, self.head_channels, -1)\n",
    "        \n",
    "        att = keys.transpose(-2, -1) @ queries\n",
    "        \n",
    "        indices = self.relative_indices.expand(self.heads, -1)\n",
    "        rel_pos_enc = self.pos_enc.gather(-1, indices)\n",
    "        rel_pos_enc = rel_pos_enc.unflatten(-1, (h * w, h * w))\n",
    "        \n",
    "        att = att * self.scale + rel_pos_enc\n",
    "        att = F.softmax(att, dim=-2)\n",
    "        \n",
    "        out = values @ att\n",
    "        out = out.view(b, -1, h, w)\n",
    "        out = self.unifyheads(out)\n",
    "        out = self.drop(out)\n",
    "        return out\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_indices(h, w):\n",
    "        y = torch.arange(h, dtype=torch.long)\n",
    "        x = torch.arange(w, dtype=torch.long)\n",
    "        \n",
    "        y1, x1, y2, x2 = torch.meshgrid(y, x, y, x)\n",
    "        indices = (y1 - y2 + h - 1) * (2 * w - 1) + x1 - x2 + w - 1\n",
    "        indices = indices.flatten()\n",
    "        \n",
    "        return indices\n",
    "    \n",
    "class FeedForward(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, mult=4, p_drop=0.):\n",
    "        hidden_channels = in_channels * mult\n",
    "        super().__init__(\n",
    "            nn.Conv2d(in_channels, hidden_channels, 1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(hidden_channels, out_channels, 1),\n",
    "            nn.Dropout(p_drop)\n",
    "        )\n",
    "\n",
    "class TransformerBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, head_channels, shape, stride=1, p_drop=0.):\n",
    "        shape = (shape[0] // stride, shape[1] // stride)\n",
    "        super().__init__(\n",
    "            Residual(\n",
    "                LayerNormChannels(in_channels),\n",
    "                nn.MaxPool2d(stride) if stride > 1 else nn.Identity(),\n",
    "                SelfAttention2d(in_channels, out_channels, head_channels, shape, p_drop=p_drop),\n",
    "                shortcut = get_shortcut(in_channels, out_channels, stride)\n",
    "            ),\n",
    "            Residual(\n",
    "                LayerNormChannels(out_channels),\n",
    "                FeedForward(out_channels, out_channels, p_drop=p_drop)\n",
    "            )\n",
    "        )\n",
    "\n",
    "class Stem(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__(\n",
    "            ConvBlock(in_channels, out_channels, 3, stride=stride),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        )\n",
    "\n",
    "class Head(nn.Sequential):\n",
    "    def __init__(self, channels, classes, p_drop=0.):\n",
    "        super().__init__(\n",
    "            LayerNormChannels(channels),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p_drop),\n",
    "            nn.Linear(channels, classes)\n",
    "        )\n",
    "\n",
    "class BlockStack(nn.Sequential):\n",
    "    def __init__(self, num_blocks, shape, in_channels, out_channels, stride, block):\n",
    "        layers = []\n",
    "        for _ in range(num_blocks):\n",
    "            layers.append(block(in_channels, out_channels, shape=shape, stride=stride))\n",
    "            shape = (shape[0] // stride, shape[1] // stride)\n",
    "            in_channels = out_channels\n",
    "            stride=1\n",
    "        super().__init__(*layers)\n",
    "\n",
    "class CoAtNet(nn.Sequential):\n",
    "    def __init__(self, classes, image_size, head_channels, channel_list, num_blocks, strides=None,\n",
    "                 in_channels=1, trans_p_drop=0., head_p_drop=0.):\n",
    "        if strides is None: strides = [2] * len(num_blocks)\n",
    "        \n",
    "        block_list = [MBConv,    # S1\n",
    "                      MBConv,    # S2\n",
    "                      Partial(TransformerBlock, head_channels, p_drop=trans_p_drop), # S3\n",
    "                      Partial(TransformerBlock, head_channels, p_drop=trans_p_drop)] # S4\n",
    "        \n",
    "        layers = [Stem(in_channels, channel_list[0], strides[0])] # S0\n",
    "        in_channels = channel_list[0]\n",
    "        \n",
    "        shape = (image_size, image_size)\n",
    "        for num, out_channels, stride, block in zip(num_blocks, channel_list[1:], strides[1:], block_list):\n",
    "            layers.append(BlockStack(num, shape, in_channels, out_channels, stride, block))\n",
    "            shape = (shape[0] // stride, shape[1] // stride)\n",
    "            in_channels = out_channels\n",
    "            \n",
    "        layers.append(Head(in_channels, classes, p_drop=head_p_drop))\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_parameters(model):\n",
    "    parameters_decay = set()\n",
    "    parameters_no_decay = set()\n",
    "    modules_weight_decay = (nn.Linear, nn.Conv2d)\n",
    "    modules_no_weight_decay = (nn.LayerNorm, nn.BatchNorm2d)\n",
    "    \n",
    "    for m_name, m in model.named_modules():\n",
    "        for param_name, param in m.named_parameters():\n",
    "            full_param_name = f\"{m_name}.{param_name}\" if m_name else param_name\n",
    "\n",
    "            if isinstance(m, modules_no_weight_decay):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif param_name.endswith(\"bias\"):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif isinstance(m, Residual) and param_name.endswith(\"gamma\"):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif isinstance(m, SelfAttention2d) and param_name.endswith(\"pos_enc\"):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif isinstance(m, modules_weight_decay):\n",
    "                parameters_decay.add(full_param_name)\n",
    "    \n",
    "    # sanity check\n",
    "    assert len(parameters_decay & parameters_no_decay) == 0\n",
    "    assert len(parameters_decay) + len(parameters_no_decay) == len(list(model.parameters()))\n",
    "\n",
    "    return parameters_decay, parameters_no_decay\n",
    "\n",
    "def get_optimizer(model, learning_rate, weight_decay):\n",
    "    param_dict = {pn: p for pn, p in model.named_parameters()}\n",
    "    parameters_decay, parameters_no_decay = separate_parameters(model)\n",
    "    \n",
    "    optim_groups = [\n",
    "        {\"params\": [param_dict[pn] for pn in parameters_decay], \"weight_decay\": weight_decay},\n",
    "        {\"params\": [param_dict[pn] for pn in parameters_no_decay], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    optimizer = optim.AdamW(optim_groups, lr=learning_rate)\n",
    "    return optimizer\n",
    "\n",
    "def print_res():\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"train loss\")\n",
    "    \n",
    "    plt.plot(list(result_dict['train_data_loss']))\n",
    "    plt.plot(list(result_dict['val_data_loss']))\n",
    "    plt.legend([\"train loss\", \"val loss\"], loc =  \"best\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(list(result_dict['train_data_acc']))\n",
    "    plt.plot(list(result_dict['val_data_acc']))\n",
    "    plt.legend([\"train acc\", \"val acc\"], loc =  \"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinhyunpark/miniconda3/lib/python3.12/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CoAtNet(\n",
       "  (0): Stem(\n",
       "    (0): ConvBlock(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "    )\n",
       "    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (1): BlockStack(\n",
       "    (0): MBConv(\n",
       "      (shortcut): Identity()\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): ConvBlock(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (3): ConvBlock(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (4): SqueezeExciteBlock(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (5): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (shortcut): Identity()\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): ConvBlock(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (3): ConvBlock(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (4): SqueezeExciteBlock(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (5): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): BlockStack(\n",
       "    (0): MBConv(\n",
       "      (shortcut): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): ConvBlock(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (3): ConvBlock(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (4): SqueezeExciteBlock(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (5): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (shortcut): Identity()\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): ConvBlock(\n",
       "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (3): ConvBlock(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (4): SqueezeExciteBlock(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (5): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): BlockStack(\n",
       "    (0): TransformerBlock(\n",
       "      (0): Residual(\n",
       "        (shortcut): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (residual): Sequential(\n",
       "          (0): LayerNormChannels(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (2): SelfAttention2d(\n",
       "            (to_keys): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (to_queries): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (to_values): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (unifyheads): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Residual(\n",
       "        (shortcut): Identity()\n",
       "        (residual): Sequential(\n",
       "          (0): LayerNormChannels(\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (3): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): Residual(\n",
       "        (shortcut): Identity()\n",
       "        (residual): Sequential(\n",
       "          (0): LayerNormChannels(\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): Identity()\n",
       "          (2): SelfAttention2d(\n",
       "            (to_keys): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (to_queries): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (to_values): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (unifyheads): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Residual(\n",
       "        (shortcut): Identity()\n",
       "        (residual): Sequential(\n",
       "          (0): LayerNormChannels(\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (3): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): BlockStack(\n",
       "    (0): TransformerBlock(\n",
       "      (0): Residual(\n",
       "        (shortcut): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (residual): Sequential(\n",
       "          (0): LayerNormChannels(\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (2): SelfAttention2d(\n",
       "            (to_keys): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (to_queries): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (to_values): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (unifyheads): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Residual(\n",
       "        (shortcut): Identity()\n",
       "        (residual): Sequential(\n",
       "          (0): LayerNormChannels(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (3): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): Residual(\n",
       "        (shortcut): Identity()\n",
       "        (residual): Sequential(\n",
       "          (0): LayerNormChannels(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): Identity()\n",
       "          (2): SelfAttention2d(\n",
       "            (to_keys): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (to_queries): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (to_values): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (unifyheads): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Residual(\n",
       "        (shortcut): Identity()\n",
       "        (residual): Sequential(\n",
       "          (0): LayerNormChannels(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (3): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Head(\n",
       "    (0): LayerNormChannels(\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): AdaptiveAvgPool2d(output_size=1)\n",
       "    (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = \"CoAtNet_Zoom_36.pkl\" \n",
    "\n",
    "model = CoAtNet(NUM_CLASSES, IMAGE_SIZE, head_channels=32, channel_list=[64, 64, 128, 256, 512],\n",
    "                num_blocks=[2, 2, 2, 2, 2], strides=[1, 1, 2, 2, 2],\n",
    "                trans_p_drop=0.3, head_p_drop=0.3)\n",
    "model.to(DEVICE)\n",
    "model.apply(init_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, val_loss):\n",
    "        print(\"val_loss, best_loss\", val_loss, self.best_loss)\n",
    "        if self.best_loss == None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            # reset counter if validation loss improves\n",
    "            self.counter = 0\n",
    "        elif self.best_loss - val_loss < self.min_delta:\n",
    "            self.counter += 1\n",
    "            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                print('INFO: Early stopping')\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = get_optimizer(model, learning_rate=1e-6, weight_decay=WEIGHT_DECAY)\n",
    "    lr_scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LEARNING_RATE,\n",
    "                                                 steps_per_epoch=len(train_loader), epochs=EPOCHS)\n",
    "\n",
    "    num_epochs = EPOCHS\n",
    "    device = DEVICE\n",
    "    early_stopping = EarlyStopping(patience=45, min_delta=0)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        result_dict['epochs'].append(epoch)\n",
    "        model.train()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        result_dict['train_data_loss'].append(loss.item())\n",
    "        result_dict['train_data_acc'].append(correct/total)\n",
    "\n",
    "        # Validation\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for inputs, labels in val_loader:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    \n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "                print(f\"Validation Accuracy: {correct/total}\")\n",
    "                result_dict['val_data_loss'].append(loss.item())\n",
    "                result_dict['val_data_acc'].append(correct/total)\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print_res()\n",
    "        \n",
    "        # early stopping\n",
    "        early_stopping(loss.item())\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"We are at epoch:\", epoch)\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            print(\"model has been saved at path:\", MODEL_PATH)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 27\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     29\u001b[0m lr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
