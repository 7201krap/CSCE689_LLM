{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import wavfile\n",
    "from functools import reduce\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64\n",
    "NUM_CLASSES = 36 # 26 + 10\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 5e-4\n",
    "WEIGHT_DECAY = 1e-1\n",
    "EPOCHS = 1100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"mps\") \n",
    "print(\"device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolator(signal, sample_rate, size, scan, before, after, threshold, show=False):\n",
    "    strokes = []\n",
    "    # -- signal'\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(signal, sr=sample_rate)\n",
    "    fft = librosa.stft(signal, n_fft=size, hop_length=scan)\n",
    "    energy = np.abs(np.sum(fft, axis=0)).astype(float)\n",
    "    # norm = np.linalg.norm(energy)\n",
    "    # energy = energy/norm\n",
    "    # -- energy'\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(energy)\n",
    "    threshed = energy > threshold\n",
    "    # -- peaks'\n",
    "    if show:\n",
    "        plt.figure(figsize=(7, 2))\n",
    "        librosa.display.waveshow(threshed.astype(float))\n",
    "    peaks = np.where(threshed == True)[0]\n",
    "    peak_count = len(peaks)\n",
    "    prev_end = sample_rate*0.1*(-1)\n",
    "    # '-- isolating keystrokes'\n",
    "    for i in range(peak_count):\n",
    "        this_peak = peaks[i]\n",
    "        timestamp = (this_peak*scan) + size//2\n",
    "        if timestamp > prev_end + (0.1*sample_rate):\n",
    "            keystroke = signal[timestamp-before:timestamp+after]\n",
    "            strokes.append(torch.tensor(keystroke)[None, :])\n",
    "            if show:\n",
    "                plt.figure(figsize=(7, 2))\n",
    "                librosa.display.waveshow(keystroke, sr=sample_rate)\n",
    "            prev_end = timestamp+after\n",
    "    return strokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:01, 24.86it/s]\n"
     ]
    }
   ],
   "source": [
    "AUDIO_FILE = '../dataset/MBPWavs/'\n",
    "keys_s = '1234567890qwertyuiopasdfghjklzxcvbnm'\n",
    "labels = list(keys_s)\n",
    "keys = [k + '.wav' for k in labels]\n",
    "data_dict = {'Key':[], 'File':[]}\n",
    "\n",
    "for i, File in tqdm(enumerate(keys)):\n",
    "    loc = AUDIO_FILE + File\n",
    "    samples, sample_rate = librosa.load(loc, sr=None)\n",
    "    #samples = samples[round(1*sample_rate):]\n",
    "    strokes = []\n",
    "    prom = 0.06\n",
    "    step = 0.005\n",
    "    while not len(strokes) == 25:\n",
    "        strokes = isolator(samples[1*sample_rate:], sample_rate, 48, 24, 2400, 12000, prom, False)\n",
    "        if len(strokes) < 25:\n",
    "            prom -= step\n",
    "        if len(strokes) > 25:\n",
    "            prom += step\n",
    "        if prom <= 0:\n",
    "            print('-- not possible for: ',File)\n",
    "            break\n",
    "        step = step*0.99\n",
    "    label = [labels[i]]*len(strokes)\n",
    "    data_dict['Key'] += label\n",
    "    data_dict['File'] += strokes\n",
    "\n",
    "df = pd.DataFrame(data_dict)\n",
    "mapper = {}\n",
    "counter = 0\n",
    "for l in df['Key']:\n",
    "    if not l in mapper:\n",
    "        mapper[l] = counter\n",
    "        counter += 1\n",
    "df.replace({'Key': mapper}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Rate --> \n",
      " 32000\n",
      "--------------------------------------------------\n",
      "data_frame.head() --> \n",
      "   Key                                               File\n",
      "0   0  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...\n",
      "1   0  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...\n",
      "2   0  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...\n",
      "3   0  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...\n",
      "4   0  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Key     900 non-null    object\n",
      " 1   File    900 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 14.2+ KB\n",
      "data_frame.info() --> \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample Rate --> \\n\", sample_rate)\n",
    "sr = sample_rate\n",
    "print(\"-\"*50)\n",
    "print(\"data_frame.head() --> \\n\", df.head())\n",
    "print(\"-\"*50)\n",
    "print(\"data_frame.info() --> \\n\", df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_name, transform = None, aug = None):\n",
    "        df = file_name\n",
    "        self.transform = transform\n",
    "        self.aug = aug\n",
    "        self.labels = df['Key']\n",
    "        self.values = df['File']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels.iloc[index]\n",
    "        value = self.values.iloc[index]\n",
    "        waveform = self.values.iloc[index]\n",
    "        label = self.labels.iloc[index]\n",
    "        if self.transform:\n",
    "            waveform = waveform.numpy()\n",
    "            waveform = waveform.flatten()\n",
    "            waveform = self.transform(waveform)\n",
    "        if self.aug:\n",
    "            waveform = self.aug(waveform)\n",
    "        return waveform, label\n",
    "\n",
    "class ToMelSpectrogram:\n",
    "    def __call__(self, samples):\n",
    "#         samples = np.array(samples)\n",
    "        spec = librosa.feature.melspectrogram(y = samples, sr = sr, n_mels=64, n_fft=1024, hop_length=226)\n",
    "        return librosa.power_to_db(spec)\n",
    "\n",
    "class TimeShifting():\n",
    "    def __call__(self, samples):\n",
    "        samples = samples.numpy()\n",
    "        samples = samples.flatten()\n",
    "        \n",
    "        shift = int(len(samples) * 0.4)\n",
    "        random_shift =random.randint(0, shift)\n",
    "        data_roll = np.roll(samples, random_shift)\n",
    "        return data_roll\n",
    "    \n",
    "class SpecAugment():\n",
    "    def __call__(self, samples):\n",
    "        num_mask = 2\n",
    "        freq_masking_max_percentage=0.10\n",
    "        time_masking_max_percentage=0.10\n",
    "        spec = samples.copy()\n",
    "        mean_value = spec.mean()\n",
    "        for i in range(num_mask):\n",
    "            all_frames_num, all_freqs_num = spec.shape[1], spec.shape[1] \n",
    "            freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n",
    "\n",
    "            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "            f0 = int(f0)\n",
    "            spec[:, f0:f0 + num_freqs_to_mask] = mean_value\n",
    "\n",
    "            time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "\n",
    "            num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "            t0 = int(t0)\n",
    "            spec[t0:t0 + num_frames_to_mask, :] = mean_value\n",
    "        return spec\n",
    "\n",
    "aug = Compose([\n",
    "    TimeShifting(),\n",
    "    ToMelSpectrogram(),\n",
    "    SpecAugment(),\n",
    "    ToTensor()\n",
    "    ])\n",
    "\n",
    "transform = Compose([\n",
    "    ToMelSpectrogram(),\n",
    "    ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train, aug = aug)\n",
    "val_dataset = MyDataset(test, transform = transform)\n",
    "train_loader = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.imshow(train_dataset[0][0][0], cmap='viridis')\n",
    "print(train_dataset[0][0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {'epochs':[], 'train_data_loss':[], \"train_data_acc\":[], 'val_data_acc':[], 'val_data_loss':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_linear(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None: nn.init.zeros_(m.bias)\n",
    "\n",
    "class Partial:\n",
    "    def __init__(self, module, *args, **kwargs):\n",
    "        self.module = module\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, *args_c, **kwargs_c):\n",
    "        return self.module(*args_c, *self.args, **kwargs_c, **self.kwargs)\n",
    "\n",
    "class LayerNormChannels(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, -1)\n",
    "        x = self.norm(x)\n",
    "        x = x.transpose(-1, 1)\n",
    "        return x\n",
    "    \n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, *layers, shortcut=None):\n",
    "        super().__init__()\n",
    "        self.shortcut = nn.Identity() if shortcut is None else shortcut\n",
    "        self.residual = nn.Sequential(*layers)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.shortcut(x) + self.gamma * self.residual(x)\n",
    "    \n",
    "class ConvBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, groups=1):\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        super().__init__(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding,\n",
    "                      groups=groups, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "def get_shortcut(in_channels, out_channels, stride):\n",
    "    if (in_channels == out_channels and stride == 1):\n",
    "        shortcut = nn.Identity()\n",
    "    else:\n",
    "        shortcut = nn.Conv2d(in_channels, out_channels, 1)\n",
    "\n",
    "    if stride > 1:\n",
    "        shortcut = nn.Sequential(nn.MaxPool2d(stride), shortcut)\n",
    "    \n",
    "    return shortcut\n",
    "\n",
    "class SqueezeExciteBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=4):\n",
    "        super().__init__()\n",
    "        self.out_channels = channels\n",
    "        channels_r = channels // reduction\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels_r, kernel_size=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(channels_r, channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x * self.se(x)\n",
    "    \n",
    "class MBConv(Residual):\n",
    "    def __init__(self, in_channels, out_channels, shape, kernel_size=3, stride=1, expansion_factor=4):\n",
    "        mid_channels = in_channels * expansion_factor\n",
    "        super().__init__(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.GELU(),\n",
    "            ConvBlock(in_channels, mid_channels, 1), # Pointwise\n",
    "            ConvBlock(mid_channels, mid_channels, kernel_size, stride=stride, groups=mid_channels), # Depthwise\n",
    "            SqueezeExciteBlock(mid_channels),\n",
    "            nn.Conv2d(mid_channels, out_channels, 1), # Pointwise\n",
    "            shortcut = get_shortcut(in_channels, out_channels, stride)\n",
    "        )\n",
    "\n",
    "class SelfAttention2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, head_channels, shape, p_drop=0.):\n",
    "        super().__init__()\n",
    "        self.heads = out_channels // head_channels\n",
    "        self.head_channels = head_channels\n",
    "        self.scale = head_channels**-0.5\n",
    "        \n",
    "        self.to_keys = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.to_queries = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.to_values = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.unifyheads = nn.Conv2d(out_channels, out_channels, 1)\n",
    "        \n",
    "        height, width = shape\n",
    "        self.pos_enc = nn.Parameter(torch.randn(self.heads, (2 * height - 1) * (2 * width - 1)))\n",
    "        self.register_buffer(\"relative_indices\", self.get_indices(height, width))\n",
    "\n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, _, h, w = x.shape\n",
    "        \n",
    "        keys = self.to_keys(x).view(b, self.heads, self.head_channels, -1)\n",
    "        values = self.to_values(x).view(b, self.heads, self.head_channels, -1)\n",
    "        queries = self.to_queries(x).view(b, self.heads, self.head_channels, -1)\n",
    "        \n",
    "        att = keys.transpose(-2, -1) @ queries\n",
    "        \n",
    "        indices = self.relative_indices.expand(self.heads, -1)\n",
    "        rel_pos_enc = self.pos_enc.gather(-1, indices)\n",
    "        rel_pos_enc = rel_pos_enc.unflatten(-1, (h * w, h * w))\n",
    "        \n",
    "        att = att * self.scale + rel_pos_enc\n",
    "        att = F.softmax(att, dim=-2)\n",
    "        \n",
    "        out = values @ att\n",
    "        out = out.view(b, -1, h, w)\n",
    "        out = self.unifyheads(out)\n",
    "        out = self.drop(out)\n",
    "        return out\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_indices(h, w):\n",
    "        y = torch.arange(h, dtype=torch.long)\n",
    "        x = torch.arange(w, dtype=torch.long)\n",
    "        \n",
    "        y1, x1, y2, x2 = torch.meshgrid(y, x, y, x)\n",
    "        indices = (y1 - y2 + h - 1) * (2 * w - 1) + x1 - x2 + w - 1\n",
    "        indices = indices.flatten()\n",
    "        \n",
    "        return indices\n",
    "    \n",
    "class FeedForward(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, mult=4, p_drop=0.):\n",
    "        hidden_channels = in_channels * mult\n",
    "        super().__init__(\n",
    "            nn.Conv2d(in_channels, hidden_channels, 1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(hidden_channels, out_channels, 1),\n",
    "            nn.Dropout(p_drop)\n",
    "        )\n",
    "\n",
    "class TransformerBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, head_channels, shape, stride=1, p_drop=0.):\n",
    "        shape = (shape[0] // stride, shape[1] // stride)\n",
    "        super().__init__(\n",
    "            Residual(\n",
    "                LayerNormChannels(in_channels),\n",
    "                nn.MaxPool2d(stride) if stride > 1 else nn.Identity(),\n",
    "                SelfAttention2d(in_channels, out_channels, head_channels, shape, p_drop=p_drop),\n",
    "                shortcut = get_shortcut(in_channels, out_channels, stride)\n",
    "            ),\n",
    "            Residual(\n",
    "                LayerNormChannels(out_channels),\n",
    "                FeedForward(out_channels, out_channels, p_drop=p_drop)\n",
    "            )\n",
    "        )\n",
    "\n",
    "class Stem(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__(\n",
    "            ConvBlock(in_channels, out_channels, 3, stride=stride),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        )\n",
    "\n",
    "class Head(nn.Sequential):\n",
    "    def __init__(self, channels, classes, p_drop=0.):\n",
    "        super().__init__(\n",
    "            LayerNormChannels(channels),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p_drop),\n",
    "            nn.Linear(channels, classes)\n",
    "        )\n",
    "\n",
    "class BlockStack(nn.Sequential):\n",
    "    def __init__(self, num_blocks, shape, in_channels, out_channels, stride, block):\n",
    "        layers = []\n",
    "        for _ in range(num_blocks):\n",
    "            layers.append(block(in_channels, out_channels, shape=shape, stride=stride))\n",
    "            shape = (shape[0] // stride, shape[1] // stride)\n",
    "            in_channels = out_channels\n",
    "            stride=1\n",
    "        super().__init__(*layers)\n",
    "\n",
    "class CoAtNet(nn.Sequential):\n",
    "    def __init__(self, classes, image_size, head_channels, channel_list, num_blocks, strides=None,\n",
    "                 in_channels=1, trans_p_drop=0., head_p_drop=0.):\n",
    "        if strides is None: strides = [2] * len(num_blocks)\n",
    "        \n",
    "        block_list = [MBConv,    # S1\n",
    "                      MBConv,    # S2\n",
    "                      Partial(TransformerBlock, head_channels, p_drop=trans_p_drop), # S3\n",
    "                      Partial(TransformerBlock, head_channels, p_drop=trans_p_drop)] # S4\n",
    "        \n",
    "        layers = [Stem(in_channels, channel_list[0], strides[0])] # S0\n",
    "        in_channels = channel_list[0]\n",
    "        \n",
    "        shape = (image_size, image_size)\n",
    "        for num, out_channels, stride, block in zip(num_blocks, channel_list[1:], strides[1:], block_list):\n",
    "            layers.append(BlockStack(num, shape, in_channels, out_channels, stride, block))\n",
    "            shape = (shape[0] // stride, shape[1] // stride)\n",
    "            in_channels = out_channels\n",
    "            \n",
    "        layers.append(Head(in_channels, classes, p_drop=head_p_drop))\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_parameters(model):\n",
    "    parameters_decay = set()\n",
    "    parameters_no_decay = set()\n",
    "    modules_weight_decay = (nn.Linear, nn.Conv2d)\n",
    "    modules_no_weight_decay = (nn.LayerNorm, nn.BatchNorm2d)\n",
    "    \n",
    "    for m_name, m in model.named_modules():\n",
    "        for param_name, param in m.named_parameters():\n",
    "            full_param_name = f\"{m_name}.{param_name}\" if m_name else param_name\n",
    "\n",
    "            if isinstance(m, modules_no_weight_decay):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif param_name.endswith(\"bias\"):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif isinstance(m, Residual) and param_name.endswith(\"gamma\"):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif isinstance(m, SelfAttention2d) and param_name.endswith(\"pos_enc\"):\n",
    "                parameters_no_decay.add(full_param_name)\n",
    "            elif isinstance(m, modules_weight_decay):\n",
    "                parameters_decay.add(full_param_name)\n",
    "    \n",
    "    # sanity check\n",
    "    assert len(parameters_decay & parameters_no_decay) == 0\n",
    "    assert len(parameters_decay) + len(parameters_no_decay) == len(list(model.parameters()))\n",
    "\n",
    "    return parameters_decay, parameters_no_decay\n",
    "\n",
    "def get_optimizer(model, learning_rate, weight_decay):\n",
    "    param_dict = {pn: p for pn, p in model.named_parameters()}\n",
    "    parameters_decay, parameters_no_decay = separate_parameters(model)\n",
    "    \n",
    "    optim_groups = [\n",
    "        {\"params\": [param_dict[pn] for pn in parameters_decay], \"weight_decay\": weight_decay},\n",
    "        {\"params\": [param_dict[pn] for pn in parameters_no_decay], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    optimizer = optim.AdamW(optim_groups, lr=learning_rate)\n",
    "    return optimizer\n",
    "\n",
    "def print_res():\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"train loss\")\n",
    "    \n",
    "    plt.plot(list(result_dict['train_data_loss']))\n",
    "    plt.plot(list(result_dict['val_data_loss']))\n",
    "    plt.legend([\"train loss\", \"val loss\"], loc =  \"best\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(list(result_dict['train_data_acc']))\n",
    "    plt.plot(list(result_dict['val_data_acc']))\n",
    "    plt.legend([\"train acc\", \"val acc\"], loc =  \"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinhyunpark/miniconda3/lib/python3.12/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CoAtNet(\n",
       "  (0): Stem(\n",
       "    (0): ConvBlock(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "    )\n",
       "    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (1): BlockStack(\n",
       "    (0): MBConv(\n",
       "      (shortcut): Identity()\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): ConvBlock(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (3): ConvBlock(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (4): SqueezeExciteBlock(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (5): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (shortcut): Identity()\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): ConvBlock(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (3): ConvBlock(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (4): SqueezeExciteBlock(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (5): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): BlockStack(\n",
       "    (0): MBConv(\n",
       "      (shortcut): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): ConvBlock(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (3): ConvBlock(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (4): SqueezeExciteBlock(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (5): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (shortcut): Identity()\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): ConvBlock(\n",
       "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (3): ConvBlock(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (4): SqueezeExciteBlock(\n",
       "          (se): Sequential(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (4): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (5): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): BlockStack(\n",
       "    (0): TransformerBlock(\n",
       "      (0): Residual(\n",
       "        (shortcut): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (residual): Sequential(\n",
       "          (0): LayerNormChannels(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (2): SelfAttention2d(\n",
       "            (to_keys): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (to_queries): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (to_values): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (unifyheads): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Residual(\n",
       "        (shortcut): Identity()\n",
       "        (residual): Sequential(\n",
       "          (0): LayerNormChannels(\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (3): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): Residual(\n",
       "        (shortcut): Identity()\n",
       "        (residual): Sequential(\n",
       "          (0): LayerNormChannels(\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): Identity()\n",
       "          (2): SelfAttention2d(\n",
       "            (to_keys): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (to_queries): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (to_values): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (unifyheads): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Residual(\n",
       "        (shortcut): Identity()\n",
       "        (residual): Sequential(\n",
       "          (0): LayerNormChannels(\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (3): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): BlockStack(\n",
       "    (0): TransformerBlock(\n",
       "      (0): Residual(\n",
       "        (shortcut): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (residual): Sequential(\n",
       "          (0): LayerNormChannels(\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (2): SelfAttention2d(\n",
       "            (to_keys): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (to_queries): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (to_values): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (unifyheads): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Residual(\n",
       "        (shortcut): Identity()\n",
       "        (residual): Sequential(\n",
       "          (0): LayerNormChannels(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (3): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (0): Residual(\n",
       "        (shortcut): Identity()\n",
       "        (residual): Sequential(\n",
       "          (0): LayerNormChannels(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): Identity()\n",
       "          (2): SelfAttention2d(\n",
       "            (to_keys): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (to_queries): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (to_values): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (unifyheads): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Residual(\n",
       "        (shortcut): Identity()\n",
       "        (residual): Sequential(\n",
       "          (0): LayerNormChannels(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (3): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Head(\n",
       "    (0): LayerNormChannels(\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): AdaptiveAvgPool2d(output_size=1)\n",
       "    (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = \"CoAtNet_Zoom_36.pkl\" \n",
    "\n",
    "model = CoAtNet(NUM_CLASSES, IMAGE_SIZE, head_channels=32, channel_list=[64, 64, 128, 256, 512],\n",
    "                num_blocks=[2, 2, 2, 2, 2], strides=[1, 1, 2, 2, 2],\n",
    "                trans_p_drop=0.3, head_p_drop=0.3)\n",
    "model.to(DEVICE)\n",
    "model.apply(init_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, val_loss):\n",
    "        print(\"val_loss, best_loss\", val_loss, self.best_loss)\n",
    "        if self.best_loss == None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            # reset counter if validation loss improves\n",
    "            self.counter = 0\n",
    "        elif self.best_loss - val_loss < self.min_delta:\n",
    "            self.counter += 1\n",
    "            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                print('INFO: Early stopping')\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = get_optimizer(model, learning_rate=1e-6, weight_decay=WEIGHT_DECAY)\n",
    "    lr_scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LEARNING_RATE,\n",
    "                                                 steps_per_epoch=len(train_loader), epochs=EPOCHS)\n",
    "\n",
    "    num_epochs = EPOCHS\n",
    "    device = DEVICE\n",
    "    early_stopping = EarlyStopping(patience=45, min_delta=0)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        result_dict['epochs'].append(epoch)\n",
    "        model.train()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        result_dict['train_data_loss'].append(loss.item())\n",
    "        result_dict['train_data_acc'].append(correct/total)\n",
    "\n",
    "        # Validation\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for inputs, labels in val_loader:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    \n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "                print(f\"Validation Accuracy: {correct/total}\")\n",
    "                result_dict['val_data_loss'].append(loss.item())\n",
    "                result_dict['val_data_acc'].append(correct/total)\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print_res()\n",
    "        \n",
    "        # early stopping\n",
    "        early_stopping(loss.item())\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"We are at epoch:\", epoch)\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            print(\"model has been saved at path:\", MODEL_PATH)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1100], Loss: 4.166524410247803\n",
      "Validation Accuracy: 0.03888888888888889\n",
      "val_loss, best_loss 3.379075527191162 None\n",
      "Epoch [2/1100], Loss: 4.145037651062012\n",
      "Validation Accuracy: 0.03888888888888889\n",
      "val_loss, best_loss 3.4697659015655518 3.379075527191162\n",
      "INFO: Early stopping counter 1 of 45\n",
      "Epoch [3/1100], Loss: 3.843966484069824\n",
      "Validation Accuracy: 0.016666666666666666\n",
      "val_loss, best_loss 3.6185121536254883 3.379075527191162\n",
      "INFO: Early stopping counter 2 of 45\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 27\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     29\u001b[0m lr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
